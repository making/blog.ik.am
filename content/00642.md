---
title: Tanzu Kubernetes Grid on vSphereを1.2.1 -> 1.3.0にアップデートするメモ
tags: ["Kubernetes", "vSphere", "TKG", "Tanzu", "Cluster API"]
categories: ["Dev", "CaaS", "Kubernetes", "TKG", "vSphere"]
---

"[Tanzu Kubernetes Grid on vSphereを1.2.0 -> 1.2.1にアップデートするメモ](/entries/631)"で作成した環境をアップデートします。

アップデートの手順はこちら
https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.3/vmware-tanzu-kubernetes-grid-13/GUID-upgrade-tkg-index.html

Release Noteはこちら
https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.3/rn/VMware-Tanzu-Kubernetes-Grid-13-Release-Notes.html

**Table of contents**
<!-- toc -->

### CLIのインストール

[https://my.vmware.com/en/web/vmware/downloads/details?downloadGroup=TKG-130&productId=988&rPId=61886](https://my.vmware.com/en/web/vmware/downloads/details?downloadGroup=TKG-130&productId=988&rPId=61886)

から

- VMware Tanzu CLI for Mac

をダウンロードして次のようにインストールしてください。1.3からCLIが`tkg`から`tanzu`に変わりました。

```
tar xvf tanzu-cli-bundle-darwin-amd64.tar

install cli/core/v1.3.0/tanzu-core-darwin_amd64 /usr/local/bin/tanzu
tanzu plugin clean
tanzu plugin install -u --local cli all
```

次のバージョンで動作確認します。

```
$ tanzu version
version: v1.3.0
buildDate: 2021-03-19
sha: 06ddc9a
```

プラグイン一覧を確認します。

```
$ tanzu plugin list                      
  NAME                LATEST VERSION  DESCRIPTION                                                        REPOSITORY  VERSION  STATUS         
  alpha               v1.3.0          Alpha CLI commands                                                 core                 not installed  
  cluster             v1.3.0          Kubernetes cluster operations                                      core        v1.3.0   installed      
  login               v1.3.0          Login to the platform                                              core        v1.3.0   installed      
  pinniped-auth       v1.3.0          Pinniped authentication operations (usually not directly invoked)  core        v1.3.0   installed      
  kubernetes-release  v1.3.0          Kubernetes release operations                                      core        v1.3.0   installed      
  management-cluster  v1.3.0          Kubernetes management cluster operations   
```

### vCenterにOVAファイルをアップロード

[https://my.vmware.com/en/web/vmware/downloads/details?downloadGroup=TKG-130&productId=988&rPId=61886](https://my.vmware.com/en/web/vmware/downloads/details?downloadGroup=TKG-130&productId=988&rPId=61886)

から

- Photon v3 Kubernetes v1.20.4 OVA

をダウンロードし、`~/Downloads`に保存します。

> なお、TKG 1.3からはPhoton OS以外にもUbuntu 2004がサポートされました。多くの人にとってはUbuntuの方が慣れていて良いかもしれません。<br>
> 自分は500MBほどサイズが小さいためPhotonを選択しました。

TKGをインストールする環境の情報を次の例のように設定してください。

```
cat <<EOF > tkg-env.sh
export GOVC_URL=vcsa.v.maki.lol
export GOVC_USERNAME=administrator@vsphere.local
export GOVC_PASSWORD=VMware1!
export GOVC_DATACENTER=Datacenter
export GOVC_NETWORK="VM Network"
export GOVC_DATASTORE=datastore1
export GOVC_RESOURCE_POOL=/Datacenter/host/Cluster/Resources/tkg
export GOVC_INSECURE=1
export TEMPLATE_FOLDER=/Datacenter/vm/tkg
EOF
```

次のコマンドでOVAファイルをvCenterにアップロードします。

```
source tkg-env.sh
govc import.ova -folder $TEMPLATE_FOLDER ~/Downloads/photon-3-kube-v1.20.4-vmware.1-tkg.0-2326554155028348692.ova 
govc vm.markastemplate $TEMPLATE_FOLDER/photon-3-kube-v1.20.4
```

### Management Clusterをアップデート

TKG 1.2の時の設定ファイルをimportします。

```
$ tanzu management-cluster import -f ~/.tkg/config.yaml

the old providers folder /Users/toshiaki/.tkg/providers is backed up to /Users/toshiaki/.tkg/providers-20210326110845-jhn6kgmj
successfully imported server: carrot

Management cluster configuration imported successfully
```

旧ファイルが`/Users/toshiaki/.tkg/providers-20210326110845-jhn6kgmj`にバックアップされてたことがログからわかります。

TKG 1.2で`~/.tkg/providers/infrastructure-vsphere/ytt/vsphere-overlay.yaml`にyttのOverlayを記述してカスタマイズしていた場合は、`tanzu management-cluster import`を実行しても移行されないので、
次のコマンドでコピーする必要があります。

```
cp -r ~/.tkg/providers-20210326110845-jhn6kgmj/infrastructure-vsphere/ytt/vsphere-overlay.yaml ~/.tanzu/tkg/providers/infrastructure-vsphere/ytt/vsphere-overlay.yaml
```

> TKG 1.2で必要であったoverlayが1.3でも必要とは限りません。1.2用のworkaroundが1.3では修正されているケースがあります。<br>
> `tanzu cluster create --dry-run`コマンドでoverlayがある場合とない場合の差分を確認してからoverlayを1.3でも使用するかどうか判断すると良いです。

Management Clusterにログインします。

```
$ tanzu login --server carrot
✔  successfully logged in to management cluster using the kubeconfig carrot
```

Workload Cluster一覧を表示します。

```
$ tanzu cluster list --include-management-cluster
  NAME    NAMESPACE   STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES       PLAN  
  grape   default     running  1/1           5/5      v1.19.3+vmware.1  <none>      prod  
  lemon   default     running  1/1           1/1      v1.19.3+vmware.1  <none>      dev   
  orange  default     running  1/1           4/4      v1.19.3+vmware.1  <none>      dev   
  carrot  tkg-system  running  1/1           1/1      v1.19.3+vmware.1  management  dev  
```

TKG 1.2の時にManagement Clusterをアップデートする前に、kapp-controllerを削除します。kapp-controllerがインストールされていない場合はこの作業は不要です。

```
kubectl use-context carrot-admin@carrot
kubectl delete deployment kapp-controller -n kapp-controller
kubectl delete clusterrole kapp-controller-cluster-role
kubectl delete clusterrolebinding kapp-controller-cluster-role-binding
kubectl delete serviceaccount kapp-controller-sa -n kapp-controller
```


次のコマンドでManagement Clusterをアップデートします。

```
tanzu management-cluster upgrade
```

次のようなログが出力されます。

```
Upgrading management cluster 'carrot' to TKG version 'v1.3.0' with Kubernetes version 'v1.20.4+vmware.1'. Are you sure? [y/N]: y
Upgrading management cluster providers...
Checking cert-manager version...
Cert-manager is already up to date
Performing upgrade...
Deleting Provider="cluster-api" Version="" TargetNamespace="capi-system"
Installing Provider="cluster-api" Version="v0.3.14" TargetNamespace="capi-system"
Deleting Provider="bootstrap-kubeadm" Version="" TargetNamespace="capi-kubeadm-bootstrap-system"
Installing Provider="bootstrap-kubeadm" Version="v0.3.14" TargetNamespace="capi-kubeadm-bootstrap-system"
Deleting Provider="control-plane-kubeadm" Version="" TargetNamespace="capi-kubeadm-control-plane-system"
Installing Provider="control-plane-kubeadm" Version="v0.3.14" TargetNamespace="capi-kubeadm-control-plane-system"
Deleting Provider="infrastructure-vsphere" Version="" TargetNamespace="capv-system"
Installing Provider="infrastructure-vsphere" Version="v0.7.6" TargetNamespace="capv-system"
Management cluster providers upgraded successfully...
Upgrading management cluster kubernetes version...
Verifying kubernetes version...
Retrieving configuration for upgrade cluster...
Create InfrastructureTemplate for upgrade...
Upgrading control plane nodes...
Patching KubeadmControlPlane with the kubernetes version v1.20.4+vmware.1...
Waiting for kubernetes version to be updated for control plane nodes
Upgrading worker nodes...
Patching MachineDeployment with the kubernetes version v1.20.4+vmware.1...
Waiting for kubernetes version to be updated for worker nodes...
updating additional components: 'metadata/tkg,addons-management/kapp-controller,addons-management/tanzu-addons-manager,tkr/tkr-controller' ... 
Management cluster 'carrot' successfully upgraded to TKG version 'v1.3.0' with kubernetes version 'v1.20.4+vmware.1'
```

次のコマンドでManagement ClusterのみKubernetes 1.20.4にバージョンアップされたことがわかります。 

```
$ tanzu cluster list --include-management-cluster
  NAME    NAMESPACE   STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES       PLAN  
  grape   default     running  1/1           5/5      v1.19.3+vmware.1  <none>      prod  
  lemon   default     running  1/1           1/1      v1.19.3+vmware.1  <none>      dev   
  orange  default     running  1/1           4/4      v1.19.3+vmware.1  <none>      dev   
  carrot  tkg-system  running  1/1           1/1      v1.20.4+vmware.1  management  dev 
```

Pod一覧を確認します。TKG 1.2と比べて、
`tkg-system` Namespaceに`kapp-controller`と`tanzu-addons-controller-manager`が存在し、
`tkr-system` Namespaceに`kapp-controller`と`tkr-controller-manager`が存在します。


```
 $ kubectl get pod -A
NAMESPACE                           NAME                                                             READY   STATUS    RESTARTS   AGE
capi-kubeadm-bootstrap-system       capi-kubeadm-bootstrap-controller-manager-5bdd64499b-mmgng       2/2     Running   0          29m
capi-kubeadm-control-plane-system   capi-kubeadm-control-plane-controller-manager-7f89b8594d-9pz9c   2/2     Running   0          32m
capi-system                         capi-controller-manager-c4f5f9c76-qs67g                          2/2     Running   0          29m
capi-webhook-system                 capi-controller-manager-768b989cbc-f9nvb                         2/2     Running   0          29m
capi-webhook-system                 capi-kubeadm-bootstrap-controller-manager-67444bbcc9-snrck       2/2     Running   0          29m
capi-webhook-system                 capi-kubeadm-control-plane-controller-manager-5466b4d4d6-grbn4   2/2     Running   0          29m
capi-webhook-system                 capv-controller-manager-7cb98c468d-7kjsz                         2/2     Running   0          29m
capv-system                         capv-controller-manager-767cc6b6bf-stc5b                         2/2     Running   0          29m
cert-manager                        cert-manager-556f68587d-x2jjg                                    1/1     Running   0          29m
cert-manager                        cert-manager-cainjector-5bc85c4c69-x5f8z                         1/1     Running   0          29m
cert-manager                        cert-manager-webhook-7bd69dfcf8-cpftg                            1/1     Running   0          28m
kube-system                         antrea-agent-bm7lm                                               2/2     Running   3          47m
kube-system                         antrea-agent-rpkjx                                               2/2     Running   0          29m
kube-system                         antrea-controller-5d594c5cc7-44qkj                               1/1     Running   0          32m
kube-system                         coredns-5b7b55f9f8-99lfk                                         1/1     Running   0          28m
kube-system                         coredns-5b7b55f9f8-ms8mg                                         1/1     Running   0          28m
kube-system                         etcd-carrot-control-plane-dx87z                                  1/1     Running   5          42m
kube-system                         kube-apiserver-carrot-control-plane-dx87z                        1/1     Running   4          47m
kube-system                         kube-controller-manager-carrot-control-plane-dx87z               1/1     Running   0          47m
kube-system                         kube-proxy-gfnrs                                                 1/1     Running   0          30m
kube-system                         kube-proxy-xr95g                                                 1/1     Running   0          29m
kube-system                         kube-scheduler-carrot-control-plane-dx87z                        1/1     Running   0          41m
kube-system                         kube-vip-carrot-control-plane-dx87z                              1/1     Running   0          41m
kube-system                         vsphere-cloud-controller-manager-jhx6m                           1/1     Running   0          42m
kube-system                         vsphere-csi-controller-555595b64c-rplcq                          5/5     Running   0          32m
kube-system                         vsphere-csi-node-jgj4k                                           3/3     Running   0          47m
kube-system                         vsphere-csi-node-lfpcc                                           3/3     Running   0          29m
tanzu-system-auth                   dex-98957b7bb-rnbbm                                              1/1     Running   0          28m
tanzu-system-logging                fluent-bit-868n4                                                 1/1     Running   0          29m
tanzu-system-logging                fluent-bit-wb7hw                                                 1/1     Running   0          47m
tkg-system                          kapp-controller-5b845bdfdd-w4z6d                                 1/1     Running   0          27m
tkg-system                          tanzu-addons-controller-manager-75588fb8c9-5lznc                 1/1     Running   0          25m
tkr-system                          tkr-controller-manager-f7bbb4bd4-85v8x                           1/1     Running   0          27m
```

Management Clusterに`kubectl`コマンドでアクセスしてみます。

```
$ kubectl cluster-info
Kubernetes master is running at https://192.168.11.110:6443
KubeDNS is running at https://192.168.11.110:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
$ kubectl get node -o wide

NAME                           STATUS   ROLES                  AGE     VERSION            INTERNAL-IP     EXTERNAL-IP     OS-IMAGE                 KERNEL-VERSION   CONTAINER-RUNTIME
carrot-control-plane-dx87z     Ready    control-plane,master   11m     v1.20.4+vmware.1   192.168.11.50   192.168.11.50   VMware Photon OS/Linux   4.19.174-5.ph3   containerd://1.4.3
carrot-md-0-6fcdff5b49-gtw66   Ready    <none>                 5m41s   v1.20.4+vmware.1   192.168.11.52   192.168.11.52   VMware Photon OS/Linux   4.19.174-5.ph3   containerd://1.4.3
```

Containerdのバージョンは1.4.3です。[こちらの記事](https://blog.ik.am/entries/641)で紹介したworkaroundはTKG 1.3では不要です。

### Workload Clusterをアップデート
次にWorkload Clusterをアップデートします。

```
tanzu cluster kubeconfig get lemon --admin
kubectl config use-context lemon-admin@lemon
```

まずはkapp-controllerを削除します。

```
kubectl delete deployment kapp-controller -n kapp-controller
kubectl delete clusterrole kapp-controller-cluster-role
kubectl delete clusterrolebinding kapp-controller-cluster-role-binding
kubectl delete serviceaccount kapp-controller-sa -n kapp-controller
```

`tanzu cluster upgrade`でWorkload Clusterを作成します。

```
tanzu cluster upgrade lemon
```

次のようなログが出力されます。

```
Upgrading workload cluster 'lemon' to kubernetes version 'v1.20.4+vmware.1'. Are you sure? [y/N]: y
Validating configuration...
Verifying kubernetes version...
Retrieving configuration for upgrade cluster...
Create InfrastructureTemplate for upgrade...
Upgrading control plane nodes...
Patching KubeadmControlPlane with the kubernetes version v1.20.4+vmware.1...
Waiting for kubernetes version to be updated for control plane nodes
Upgrading worker nodes...
Patching MachineDeployment with the kubernetes version v1.20.4+vmware.1...
Waiting for kubernetes version to be updated for worker nodes...
updating additional components: 'metadata/tkg,addons-management/kapp-controller' ... 
Cluster 'lemon' successfully upgraded to kubernetes version 'v1.20.4+vmware.1'
```

`tkg get cluster`でWorkload Clusterを確認できます。`grape`のみKubernetes 1.19.3にバージョンアップされたことがわかります

```
$ tanzu cluster list --include-management-cluster
  NAME    NAMESPACE   STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES       PLAN  
  grape   default     running  1/1           5/5      v1.19.3+vmware.1  <none>      prod  
  lemon   default     running  1/1           1/1      v1.20.4+vmware.1  <none>      dev   
  orange  default     running  1/1           4/4      v1.19.3+vmware.1  <none>      dev   
  carrot  tkg-system  running  1/1           1/1      v1.20.4+vmware.1  management  dev
```

ここまででKubernetesのアップデートは完了しました。

#### Multi-Attach error for volumeが出た場合の対応

Upgradeの場面に限りませんが、Persistent VolumeがアタッチされたPodがVMを移動した場合に、Podが起動しない場合があります。
該当のPodを`kubectl describe pod`で確認すると、次のようなメッセージが出ている場合があります。

```
  Warning  FailedAttachVolume  15m                   attachdetach-controller  Multi-Attach error for volume "pvc-baf89fbb-cdb0-4045-8808-0e834f4125ad" Volume is already exclusively attached to one node and can't be attached to another
```

この場合のworkaroundとしては、該当のPersistent Volumeに対応するVolume Attachmentのfinalizerを空にすれば良いです。

例えば次の結果が出力される場合、

```
$ kubectl get volumeattachment
NAME                                                                   ATTACHER                 PV                                         NODE                        ATTACHED   AGE
csi-8bf82a8487bc93bb8f0ef72ac41a909105caabd93d95292aca8d20aa208eeabe   csi.vsphere.vmware.com   pvc-baf89fbb-cdb0-4045-8808-0e834f4125ad   lemon-md-0-75f769b4-hhbk6   true       10d
csi-e40b469e47532e5264da6fd5491735ec99a63056d02fdfac46437afb65fd8f87   csi.vsphere.vmware.com   pvc-a1c2f62e-eed2-40b1-9526-17695efef4e7   lemon-md-0-75f769b4-hhbk6   true       10d
```

対象のPersistent Volume `pvc-baf89fbb-cdb0-4045-8808-0e834f4125ad`に対応するVolume Attachmentは`csi-8bf82a8487bc93bb8f0ef72ac41a909105caabd93d95292aca8d20aa208eeabe`です。

このVolume Attachmentを次のコマンドdで次のように編集してください。

```
kubectl edit volumeattachment csi-8bf82a8487bc93bb8f0ef72ac41a909105caabd93d95292aca8d20aa208eeabe
```

変更前

```
apiVersion: storage.k8s.io/v1
kind: VolumeAttachment
metadata:
  annotations:
    csi.alpha.kubernetes.io/node-id: lemon-md-0-75f769b4-hhbk6
  creationTimestamp: "2021-03-26T04:33:01Z"
  finalizers:
  - external-attacher/csi-vsphere-vmware-com
  name: csi-8bf82a8487bc93bb8f0ef72ac41a909105caabd93d95292aca8d20aa208eeabe
  resourceVersion: "13761446"
  uid: b11b00ba-90e9-4355-ac2c-206fec7f3050
spec:
  attacher: csi.vsphere.vmware.com
  nodeName: lemon-md-0-75f769b4-hhbk6
  source:
    persistentVolumeName: pvc-1f0d556a-1133-4457-9675-a514cd648b92
status:
  attached: true
  attachmentMetadata:
    diskUUID: 6000c2928541ab2d9949f071053caedc
    type: vSphere CNS Block Volume
```

変更後

```
apiVersion: storage.k8s.io/v1
kind: VolumeAttachment
metadata:
  annotations:
    csi.alpha.kubernetes.io/node-id: lemon-md-0-75f769b4-hhbk6
  creationTimestamp: "2021-03-26T04:33:01Z"
  finalizers: [] # <----------- Here
  name: csi-8bf82a8487bc93bb8f0ef72ac41a909105caabd93d95292aca8d20aa208eeabe
  resourceVersion: "13761446"
  uid: b11b00ba-90e9-4355-ac2c-206fec7f3050
spec:
  attacher: csi.vsphere.vmware.com
  nodeName: lemon-md-0-75f769b4-hhbk6
  source:
    persistentVolumeName: pvc-1f0d556a-1133-4457-9675-a514cd648b92
status:
  attached: true
  attachmentMetadata:
    diskUUID: 6000c2928541ab2d9949f071053caedc
    type: vSphere CNS Block Volume
```


### Add-onの登録

TKG 1.3からはKubernetesのアップデートとCNI、vSphere CPI、vSphere CSIといった機能は"Add-on"という形で別管理になりました。

具体的にはTKG 1.3では

* CNI (Calico or [Antrea](https://github.com/vmware-tanzu/antrea))
* vSphere CPI
* vSphere CSI
* Authentication ([Pinniped](https://github.com/vmware-tanzu/pinniped))
* Metrics Server

がAdd-onとして用意されています。

このうちCNI、vSphere CPI、vSphere CSIは1.2から使えている機能ですが、`tanzu cluster upgrade`を行っただけではアップデートされないため、
個別アップデートが必要です。
PinnipedとMetrics Serverは1.3からサポートされました。インストールしたい場合はこのAdd-onを明示的に登録する必要があります。

> `tanzu cluster create`でクラスタを新規作成する場合は各Addonが自動で追加されます。

アップデート方法はこちらです
https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.3/vmware-tanzu-kubernetes-grid-13/GUID-upgrade-tkg-addons.html

今回は

* Antreaのアップデート
* vSphere CPIのアップデート
* vSphere CSIのアップデート
* Metrics Serverのインストール

を行います。


#### Management ClusterのAdd-on登録

ContextはManagement Clusterを指定します。

```
kubectl config use-context carrot-admin@carrot
```

次のコマンドで、Antrea、vSphere CPI、vSphere CSI、Metrics Serverの登録を行います。

```
# VSPHERE_CONTROL_PLANE_ENDPOINTにはダミー値を設定しないとエラーになります。

export CLUSTER_NAME=carrot
export NAMESPACE=tkg-system
export CLUSTER_PLAN=dev
export VSPHERE_CONTROL_PLANE_ENDPOINT=dummy
export _TKG_CLUSTER_FORCE_ROLE=management

export FILTER_BY_ADDON_TYPE=cni/antrea,cloud-provider/vsphere-cpi,csi/vsphere-csi,metrics/metrics-server
export REMOVE_CRS_FOR_ADDON_TYPE=cni/antrea,cloud-provider/vsphere-cpi,csi/vsphere-csi
tanzu cluster create ${CLUSTER_NAME} --dry-run -f ~/.tanzu/tkg/cluster-config.yaml > ${CLUSTER_NAME}.yml
kubectl apply -f ${CLUSTER_NAME}.yml
```

Add-onは[kapp-controller](https://github.com/vmware-tanzu/carvel-kapp-controller)によって管理されています。
次のコマンドで登録されているAdd-onを確認できます。kapp-controllerの周期間隔の設定上、インストールが始まるまでに最大5分間かかる可能性があります。

```
$ kubectl get app -n tkg-system
NAME                   DESCRIPTION           SINCE-DEPLOY   AGE
antrea                 Reconcile succeeded   85s            1d
metrics-server         Reconcile succeeded   4m37s          1d
tanzu-addons-manager   Reconcile succeeded   4m32s          1d
vsphere-csi            Reconcile succeeded   3m34s          1d
```

> Management Clusterに対して、なぜかvSphere CPIが登録されませんでした。バグかどうか現時点ではわかりません。<br>
> `~/.tanzu/tkg/providers/ytt/02_addons/cpi/cpi_secret*` を見ると確かに、Management Clusterの更新時には何も効かないように見えます。

Metrics Serverがインストールされたので`kubectl top`コマンドが利用可能になります。

```
$ kubectl top node
NAME                           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
carrot-control-plane-dx87z     254m         12%    2558Mi          88%       
carrot-md-0-6fcdff5b49-gtw66   164m         8%     1402Mi          74%

$ kubectl top pod -A
NAMESPACE                           NAME                                                             CPU(cores)   MEMORY(bytes)   
capi-kubeadm-bootstrap-system       capi-kubeadm-bootstrap-controller-manager-5bdd64499b-mmgng       1m           25Mi            
capi-kubeadm-control-plane-system   capi-kubeadm-control-plane-controller-manager-7f89b8594d-9pz9c   1m           37Mi            
capi-system                         capi-controller-manager-c4f5f9c76-qs67g                          7m           51Mi            
capi-webhook-system                 capi-controller-manager-768b989cbc-f9nvb                         1m           20Mi            
capi-webhook-system                 capi-kubeadm-bootstrap-controller-manager-67444bbcc9-snrck       1m           18Mi            
capi-webhook-system                 capi-kubeadm-control-plane-controller-manager-5466b4d4d6-grbn4   1m           15Mi            
capi-webhook-system                 capv-controller-manager-7cb98c468d-7kjsz                         1m           19Mi            
capv-system                         capv-controller-manager-767cc6b6bf-stc5b                         2m           35Mi            
cert-manager                        cert-manager-556f68587d-x2jjg                                    3m           21Mi            
cert-manager                        cert-manager-cainjector-5bc85c4c69-x5f8z                         4m           37Mi            
cert-manager                        cert-manager-webhook-7bd69dfcf8-cpftg                            3m           13Mi            
kube-system                         antrea-agent-gsd8l                                               7m           64Mi            
kube-system                         antrea-agent-zncdj                                               7m           67Mi            
kube-system                         antrea-controller-794f48f7bb-klrv9                               8m           39Mi            
kube-system                         coredns-5b7b55f9f8-99lfk                                         5m           17Mi            
kube-system                         coredns-5b7b55f9f8-ms8mg                                         5m           17Mi            
kube-system                         etcd-carrot-control-plane-dx87z                                  23m          83Mi            
kube-system                         kube-apiserver-carrot-control-plane-dx87z                        83m          836Mi           
kube-system                         kube-controller-manager-carrot-control-plane-dx87z               15m          84Mi            
kube-system                         kube-proxy-gfnrs                                                 1m           19Mi            
kube-system                         kube-proxy-xr95g                                                 1m           23Mi            
kube-system                         kube-scheduler-carrot-control-plane-dx87z                        3m           28Mi            
kube-system                         kube-vip-carrot-control-plane-dx87z                              1m           18Mi            
kube-system                         metrics-server-66544ff86b-plfh4                                  3m           19Mi            
kube-system                         vsphere-cloud-controller-manager-jhx6m                           1m           29Mi            
kube-system                         vsphere-csi-controller-7d77fb6846-c9bwz                          9m           489Mi           
kube-system                         vsphere-csi-node-9vzcj                                           1m           429Mi           
kube-system                         vsphere-csi-node-jxsnw                                           1m           432Mi           
tanzu-system-auth                   dex-98957b7bb-rnbbm                                              1m           8Mi             
tanzu-system-logging                fluent-bit-868n4                                                 14m          19Mi            
tanzu-system-logging                fluent-bit-wb7hw                                                 14m          31Mi            
tkg-system                          kapp-controller-5b845bdfdd-w4z6d                                 1m           66Mi            
tkg-system                          tanzu-addons-controller-manager-75588fb8c9-5lznc                 1m           33Mi            
tkr-system                          tkr-controller-manager-f7bbb4bd4-85v8x                           2m           22Mi
```

#### Workload ClusterのAdd-on登録
次にWorkload ClusterのAdd-onを登録します。
Contextは引き続きManagement Clusterを指定します。

```
kubectl config use-context carrot-admin@carrot
```

次のコマンドで、Antrea、vSphere CPI、vSphere CSI、Metrics Serverの登録を行います。

```
export CLUSTER_NAME=lemon
export NAMESPACE=default
export CLUSTER_PLAN=dev
export VSPHERE_CONTROL_PLANE_ENDPOINT=dummy
export _TKG_CLUSTER_FORCE_ROLE=workload

export FILTER_BY_ADDON_TYPE=cni/antrea,cloud-provider/vsphere-cpi,csi/vsphere-csi,metrics/metrics-server
export REMOVE_CRS_FOR_ADDON_TYPE=cni/antrea,cloud-provider/vsphere-cpi,csi/vsphere-csi
tanzu cluster create ${CLUSTER_NAME} --dry-run -f ~/.tanzu/tkg/cluster-config.yaml > ${CLUSTER_NAME}.yml
kubectl apply -f ${CLUSTER_NAME}.yml
```

しばらくすると全てのAdd-onが登録されていることがわかります。

```
$ kubectl get app -n tkg-system
NAME             DESCRIPTION           SINCE-DEPLOY   AGE
antrea           Reconcile succeeded   2m4s           1d
metrics-server   Reconcile succeeded   96s            1d
vsphere-cpi      Reconcile succeeded   98s            1d
vsphere-csi      Reconcile succeeded   103s           1d
```

### TKG Extensionのアップデート

TKG Extensionを使用している場合はこちらもアップデートが必要です。
ドキュメントの通りなので割愛します。

https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.3/vmware-tanzu-kubernetes-grid-13/GUID-upgrade-tkg-extensions.html

---

TKG 1.2.1 -> 1.3へのアップデートを行いました。
CLIが`tkg`から`tanzu`になり、クラスタアップデート方法が大きく変わった上に、Add-onの登録が必要になって少し面倒臭くなりました。

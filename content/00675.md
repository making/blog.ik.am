---
title: Tanzu Kubernetes Grid及びTanzu Community Editionのk8sクラスタから自己署名証明書を使ったコンテナレジストリにアクセスするメモ
tags: ["Kubernetes", "vSphere", "TKG", "Tanzu", "Cluster API", "Harbor", "TCE", "ytt", "Cartographer"]
categories: ["Dev", "CaaS", "Kubernetes", "TKG"]
---

オンプレ環境ではプライベートコンテナレジストリを使用することが多いです。
Let's Encryptを使ってコンテナレジストリをTLS化できれば、その後の使い方が簡単なのですが、
自己証明書証明書(a.k.a オレオレ証明書)を使うケースも多いです。

今回は自己証明書証明書を使った場合に、TKG/TCEのクラスタからイメージをpullできるようにするための設定方法を説明します。
コンテナレジストリにはHarborを使用します。

TKG/TCEからはコンテナレジストリへアクセスするパターンは次の図の2通り(containerd, kapp-controller)あります。
kapp controllerからもpullがあるのが盲点です。imgpkgのbundleをプライベートコンテナレジストにリロケーションしてpackageをインストールする場合に本記事の設定が必要となります。

![custom-ca](https://user-images.githubusercontent.com/106908/145676330-432b118c-6f64-49e8-a1b7-3fc1ab81e018.jpeg)


基本的には次のドキュメントの通りですが、このドキュメントの設定はcontainerdがHarborからイメージをpullするパターンにのみ対応しており、kapp controllerがHarborからイメージをpullする場合には機能しません。
またこのドキュメントはクラスタ新規作成の場合にのみ有効です。

https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-cluster-lifecycle-secrets.html#custom-ca

以降ではkapp controllerにも設定が適用されるようにしています。

TKG 1.3以下の場合は、以下の手順の `${HOME}/.config/tanzu/tkg/providers/ytt/03_customizations` を `${HOME}/.tanzu/tkg/providers/ytt/03_customizations` に読み替えてください。

なお、Tanzu PakageのHarborのインストール方法は次の記事を参照してください。
* [TKG 1.4.0の場合](/entries/673)
* [TCEの場合](/entries/674)

**目次**
<!-- toc -->

### HarborのCA証明書の取得

次のコマンドでHarborのCA証明書を取得し、`${HOME}/.config/tanzu/tkg/providers/ytt/03_customization`に配置します。

```
curl -sk https://${HARBOR_HOST}/api/v2.0/systeminfo/getcert \
 > ${HOME}/.config/tanzu/tkg/providers/ytt/03_customizations/harbor-ca.pem
```

または

```
HARBOR_NAMESPACE=tanzu-system-registry
# TCEの場合はHARBOR_NAMESPACE=harbor

kubectl get secret -n ${HARBOR_NAMESPACE} harbor-tls --template '{{index .data "ca.crt" | base64decode}}' \
 > ${HOME}/.config/tanzu/tkg/providers/ytt/03_customizations/harbor-ca.pem
```

### 追加のCA証明書を信頼するためのytt overlayファイル作成

`${HOME}/.config/tanzu/tkg/providers/ytt/03_customizations/custom-ca.yaml` に次の内容を設定します。

NodeのOSがPhotonの場合とUbuntuの場合で変更点が若干異なります。

* Photon OSの場合

```yaml
#@ load("@ytt:overlay", "overlay")
#@ load("@ytt:data", "data")

#! Trust your custom CA certificates on all Control Plane nodes.
#@overlay/match by=overlay.subset({"kind":"KubeadmControlPlane"})
---
spec:
  kubeadmConfigSpec:
    #@overlay/match missing_ok=True
    files:
    #@overlay/append
    - content: #@ data.read("harbor-ca.pem")
      owner: root:root
      permissions: "0644"
      path: /etc/ssl/certs/harbor-ca.pem
    #@overlay/match missing_ok=True
    preKubeadmCommands:
    #@overlay/append
    - '! which rehash_ca_certificates.sh 2>/dev/null || rehash_ca_certificates.sh'

#! Trust your custom CA certificates on all worker nodes.
#@overlay/match by=overlay.subset({"kind":"KubeadmConfigTemplate"}), expects="1+"
---
spec:
  template:
    spec:
      #@overlay/match missing_ok=True
      files:
      #@overlay/append
      - content: #@ data.read("harbor-ca.pem")
        owner: root:root
        permissions: "0644"
        path: /etc/ssl/certs/harbor-ca.pem
      #@overlay/match missing_ok=True
      preKubeadmCommands:
      #@overlay/append
      - '! which rehash_ca_certificates.sh 2>/dev/null || rehash_ca_certificates.sh'

#@ kapp_controller = lambda i,left,right: left["metadata"]["name"].endswith("-kapp-controller-addon")
#@ secret = overlay.subset({"kind": "Secret"})
#@overlay/match by=overlay.and_op(secret, kapp_controller), expects="1+"
---
stringData:
  #@overlay/replace via=lambda left, right: left.replace("config: {}", right)
  #@yaml/text-templated-strings
  values.yaml: |
    config: {caCerts: "(@= data.read("harbor-ca.pem").replace("\n", "\\n") @)"}
```

* Ubuntuの場合

```yaml
#@ load("@ytt:overlay", "overlay")
#@ load("@ytt:data", "data")

#! Trust your custom CA certificates on all Control Plane nodes.
#@overlay/match by=overlay.subset({"kind":"KubeadmControlPlane"})
---
spec:
  kubeadmConfigSpec:
    #@overlay/match missing_ok=True
    files:
    #@overlay/append
    - content: #@ data.read("harbor-ca.pem")
      owner: root:root
      permissions: "0644"
      path: /etc/ssl/certs/harbor-ca.pem
    #@overlay/match missing_ok=True
    preKubeadmCommands:
    #@overlay/append
    - '! which update-ca-certificates 2>/dev/null || (mv /etc/ssl/certs/harbor-ca.pem /usr/local/share/ca-certificates/tkg-custom-ca.crt && update-ca-certificates)'

#! Trust your custom CA certificates on all worker nodes.
#@overlay/match by=overlay.subset({"kind":"KubeadmConfigTemplate"}), expects="1+"
---
spec:
  template:
    spec:
      #@overlay/match missing_ok=True
      files:
      #@overlay/append
      - content: #@ data.read("harbor-ca.pem")
        owner: root:root
        permissions: "0644"
        path: /etc/ssl/certs/harbor-ca.pem
      #@overlay/match missing_ok=True
      preKubeadmCommands:
      #@overlay/append
      - '! which update-ca-certificates 2>/dev/null || (mv /etc/ssl/certs/harbor-ca.pem /usr/local/share/ca-certificates/tkg-custom-ca.crt && update-ca-certificates)'

#@ kapp_controller = lambda i,left,right: left["metadata"]["name"].endswith("-kapp-controller-addon")
#@ secret = overlay.subset({"kind": "Secret"})
#@overlay/match by=overlay.and_op(secret, kapp_controller), expects="1+"
---
stringData:
  #@overlay/replace via=lambda left, right: left.replace("config: {}", right)
  #@yaml/text-templated-strings
  values.yaml: |
    config: {caCerts: "(@= data.read("harbor-ca.pem").replace("\n", "\\n") @)"}
```

### Workload Clusterに追加のCA証明書を信頼させる

ytt overlayの適用方法はクラスタ新規作成の場合と既存のクラスタに適用する場合で異なります。

#### クラスタ新規作成の場合

新規作成の場合は簡単です。通常通り次のコマンドを実行するだけです。

```
tanzu cluster create -f ~/.config/tanzu/tkg/clusterconfigs/<CLUSTER_NAME>.yaml
```

このコマンドを実行する前にDry Runでyttのoverlayが正しく機能するかを確認した方が良いです。

```
tanzu cluster create -f ~/.config/tanzu/tkg/clusterconfigs/<CLUSTER_NAME>.yaml --dry-run
```

出力されるYAMLから`preKubeadmCommands`を検索し、次の図のように末尾にCA証明書を更新するコマンドが追加されているか確認してください。

![image](https://user-images.githubusercontent.com/106908/145662815-ad877e74-b719-48c1-8627-92b674066ee2.png)

また`kapp-controller`を検索し、次の図のように`caCerts`の設定が含まれていることを確認してください。

![image](https://user-images.githubusercontent.com/106908/145676839-6f685b11-0138-4582-9166-52f93cac33b7.png)


#### 既存クラスタ更新の場合

既存クラスタ更新の場合は少し面倒です。

まずDry Runの結果をyamlに保存します。

```
tanzu cluster create -f ~/.config/tanzu/tkg/clusterconfigs/<CLUSTER_NAME>.yaml --dry-run > patch.yaml
```

このYAMLをManagement Clusterに対して適用します。次のコマンドのように、applyする前に一度diffをとって差分が想定された内容がどうか確認してください。

```
kubectl config use-context <MANAGEMENT_CLUSTER_CONTEXT>
kubectl diff -f patch.yaml
kubectl apply -f patch.yaml
```

次のコマンドで対象のクラスタのControlplaneがRolling Updateされることを確認してください。

```
kubectl get machine -w
```

ControlplaneのVMは自動で再作成されますが、WorkerのVMは次にMachineDeploymentが変更されるタイミングで設定が反映されて再作成されます。
次のコマンドでMachineDeploymentに強制的に変更を加え、Worker VMの再作成をトリガーします。

```
kubectl patch machinedeployment <CLUSTER_NAME>-md-0 --type merge -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"date\":\"`date +'%s'`\"}}}}}"
```

VMが作成されたら`kubectl`のコンテキストを対象のWorkloadクラスタに変更し、次のコマンドを実行して、kapp controllerのConfigMapの変更が反映されていることを確認してください。

```
$ kubectl get cm -n tkg-system kapp-controller-config -ojsonpath='{.data}'   
{"caCerts":"-----BEGIN CERTIFICATE-----\nMIIDWzCCAkOgAwIBAgIRAPrItFdLgLkYO15wD8EKri0wDQYJKoZIhvcNAQELBQAw\nLTEXMBUGA1UEChMOUHJvamVjdCBIYXJib3IxEjAQBgNVBAMTCUhhcmJvciBDQTAe\nFw0yMTEyMTAxNzIyNTZaFw0zMTEyMDgxNzIyNTZaMC0xFzAVBgNVBAoTDlByb2pl\nY3QgSGFyYm9yMRIwEAYDVQQDEwlIYXJib3IgQ0EwggEiMA0GCSqGSIb3DQEBAQUA\nA4IBDwAwggEKAoIBAQC/eijyxJ63VqLQvFpMC8Ky5UaXvgUVfPaFUE7nNc7BdTkW\nTBUrju3xi3DMzOrkAlFAt4GLEmkgagMci31E2wnd2EKGcCDVYToK/XDozwpv0VHq\nvlIFiILOsGBJugaRcj+iLQ2xfkTZwB071kDkJvYxPcIdQPup+npXe4ZmZwxU+mUJ\ndAF7L8CR7ZnqiiwtMDJhxgsaf8ROsik4TuMl0SZwcdQRqkJidLqixe3pug9HgIaB\nN9lHtyjCrkeaq5inKItb7EI807CwIIBVo2ABMnVOo4jSepSfCrvmgkg+p4mB+oBs\nd8D2JIWseJ4L8VrLhMnLBW2grxzteXohSQr1h1b9AgMBAAGjdjB0MA4GA1UdDwEB\n/wQEAwICBDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwDwYDVR0TAQH/\nBAUwAwEB/zAdBgNVHQ4EFgQUKHmdszgNJPQI8dgp1eE2axRWjGwwEwYDVR0RBAww\nCoIIaGFyYm9yY2EwDQYJKoZIhvcNAQELBQADggEBAHYAAwX/KoqMRLpjKVD9IzDr\nJGnHu1xBrAQWurCURgi/bMa3On2vxep+hZ+mW7c6turf+r7V2y02mWZZ28ODq3IZ\nUIuwoc8WpuJEFDswL0Gs/j7Gr/v2eZE5MQ+nwPQJnc5eCzBQSNstvj1mdhG0jaK1\nv+HUicyYvHrHFUUl8Ee7K/q46QSNVMtLN9QSbMaz6pgmCX3Gj6+FpzgpRv4cegZY\n4dN2AdY4a6cxKmTyqUIFGKPNI0aZk5A4Ho0GVp1rUTUc6ZNE0qQDvMbQsPkXHiWK\nIbsMsnvdqa0rxu1ZkNuf2CfsOngLrDCUGaDczMqevNuZLfg0cTCSE7Ba1lLLDb0=\n-----END CERTIFICATE-----\n","dangerousSkipTLSVerify":"","httpProxy":"","httpsProxy":"","noProxy":""}
```

タイミングによってはkapp controllerがこの設定を反映できていないので、次のコマンドを実行してkapp controllerを再起動してください。

```
kubectl rollout restart -n tkg-system deployment kapp-controller
```


### containerdが追加のCA証明書を信頼していることを確認

次のコマンドでHarborにコンテナイメージをpushします。

```
docker pull gcr.io/google-samples/hello-app:1.0
docker tag gcr.io/google-samples/hello-app:1.0 ${HARBOR_HOST}/library/hello-app:1.0
docker push ${HARBOR_HOST}/library/hello-app:1.0
```

次のコマンドでpushしたコンテナイメージをk8s上に配置します。

```
kubectl run hello-app --image ${HARBOR_HOST}/library/hello-app:1.0
```

次のコマンドを実行し、`STATUS`列が`Running`になっていればOKです。

```
$ kubectl get pod -l run=hello-app
NAME        READY   STATUS    RESTARTS   AGE
hello-app   1/1     Running   0          25s
```

### kapp controllerが追加のCA証明書を信頼していることを確認

動作確認用のimgpkg bundleとして[Cartographer](https://cartographer.sh)を使用します。

次のコマンドでCartographerのbundleをHarborへrelocationします。

```
wget https://github.com/vmware-tanzu/cartographer/releases/v0.0.7/download/bundle.tar
imgpkg copy --tar bundle.tar --to-repo $HARBOR_HOST/library/cartographer-bundle --registry-ca-cert-path $HOME/.config/tanzu/tkg/providers/ytt/03_customizations/harbor-ca.pem 
```

次のように、Carvel Packageのマニフェストをダウンロードし、relocationされたのimageに変更します。

```
wget https://github.com/vmware-tanzu/cartographer/releases/download/v0.0.7/package.yaml
wget https://github.com/vmware-tanzu/cartographer/releases/download/v0.0.7/package-metadata.yaml
sed -i."" "s|index.docker.io/projectcartographer/cartographer-bundle|$HARBOR_HOST/library/cartographer-bundle|" package.yaml
```

次のコマンドを実行し、Cartographer packageを利用可能します。

```
kubectl apply -f package.yaml -f package-metadata.yaml
```

本題からそれますが、CartographerのインストールにCert Managerが必要なので、次のコマンドでCert Manager Packageをインストールします。
```
kubectl create namespace tkg-package-install
# TKGの場合
tanzu package install cert-manager --package-name cert-manager.tanzu.vmware.com --version 1.1.0+vmware.1-tkg.2 --namespace tkg-package-install
# TCEの場合
tanzu package install cert-manager --package-name cert-manager.community.tanzu.vmware.com --version 1.5.3 --namespace tkg-package-install
```

次のコマンドでCartographer Packageをインストールします。

```
tanzu package install cartographer --package-name cartographer.carto.run --version 0.0.7 --namespace tkg-package-install
```

インストールが成功したら次のコマンドで結果を確認してください。
`.status.template.stderr`にrelocation先のイメージ名が出力されていれば、HarborからCartographerをインストールできたことがわかります。

```
$ kubectl get app cartographer -oyaml
apiVersion: kappctrl.k14s.io/v1alpha1
kind: App
metadata:
  creationTimestamp: "2021-12-11T10:48:33Z"
  finalizers:
  - finalizers.kapp-ctrl.k14s.io/delete
  generation: 1
  name: cartographer
  namespace: default
  ownerReferences:
  - apiVersion: packaging.carvel.dev/v1alpha1
    blockOwnerDeletion: true
    controller: true
    kind: PackageInstall
    name: cartographer
    uid: afdc0d46-334a-4ce0-8560-2fd2acee16d1
  resourceVersion: "68441"
  uid: c344ff87-8b6a-4dbd-9767-8c63366e845c
spec:
  deploy:
  - kapp:
      rawOptions:
      - --wait-timeout=5m
  fetch:
  - imgpkgBundle:
      image: harbor-10-213-232-22.sslip.io/library/cartographer-bundle@sha256:35bfc11d92c14446863e251ad659a7232825212229d529a40d28c468c70392ec
  serviceAccountName: cartographer-default-sa
  template:
  - ytt:
      ignoreUnknownComments: true
      inline:
        paths:
          namespace.yaml: |-
            apiVersion: v1
            kind: Namespace
            metadata:
              name: cartographer-system
  - kbld: {}
status:
  conditions:
  - status: "True"
    type: ReconcileSucceeded
  consecutiveReconcileSuccesses: 1
  deploy:
    exitCode: 0
    finished: true
    startedAt: "2021-12-11T10:48:34Z"
    stdout: |-
      Target cluster 'https://100.64.0.1:443' (nodes: cheetah-control-plane-xtwcj, 1+)
      10:48:35AM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreanetworkpolicystats"}
      10:48:35AM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreaclusternetworkpolicystats"}
      10:48:35AM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"networkpolicystats"}
      Changes
      Namespace            Name                                  Kind                            Conds.  Age  Op      Op st.  Wait to    Rs  Ri
      (cluster)            cartographer-cluster-admin            ClusterRoleBinding              -       -    create  -       reconcile  -   -
      ^                    cartographer-system                   Namespace                       -       -    create  -       reconcile  -   -
      ^                    clusterconfigtemplates.carto.run      CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clusterdeliveries.carto.run           CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clusterdeploymenttemplates.carto.run  CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clusterimagetemplates.carto.run       CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clusterruntemplates.carto.run         CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clustersourcetemplates.carto.run      CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clustersupplychains.carto.run         CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    clustersupplychainvalidator           ValidatingWebhookConfiguration  -       -    create  -       reconcile  -   -
      ^                    clustertemplates.carto.run            CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    deliverables.carto.run                CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    deliveryvalidator                     ValidatingWebhookConfiguration  -       -    create  -       reconcile  -   -
      ^                    pipelines.carto.run                   CustomResourceDefinition        -       -    create  -       reconcile  -   -
      ^                    workloads.carto.run                   CustomResourceDefinition        -       -    create  -       reconcile  -   -
      cartographer-system  cartographer-controller               Deployment                      -       -    create  -       reconcile  -   -
      ^                    cartographer-controller               ServiceAccount                  -       -    create  -       reconcile  -   -
      ^                    cartographer-webhook                  Certificate                     -       -    create  -       reconcile  -   -
      ^                    cartographer-webhook                  Secret                          -       -    create  -       reconcile  -   -
      ^                    cartographer-webhook                  Service                         -       -    create  -       reconcile  -   -
      ^                    private-registry-credentials          Secret                          -       -    create  -       reconcile  -   -
      ^                    selfsigned-issuer                     Issuer                          -       -    create  -       reconcile  -   -
      Op:      22 create, 0 delete, 0 update, 0 noop
      Wait to: 22 reconcile, 0 delete, 0 noop
      10:48:35AM: ---- applying 15 changes [0/22 done] ----
      10:48:35AM: create namespace/cartographer-system (v1) cluster
      10:48:35AM: create customresourcedefinition/clusterdeploymenttemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/clusterimagetemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/clusterdeliveries.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/clustersourcetemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/clusterruntemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/clustersupplychains.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/clustertemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:35AM: create customresourcedefinition/pipelines.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:36AM: create validatingwebhookconfiguration/deliveryvalidator (admissionregistration.k8s.io/v1) cluster
      10:48:36AM: create clusterrolebinding/cartographer-cluster-admin (rbac.authorization.k8s.io/v1) cluster
      10:48:36AM: create validatingwebhookconfiguration/clustersupplychainvalidator (admissionregistration.k8s.io/v1) cluster
      10:48:36AM: create customresourcedefinition/clusterconfigtemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:36AM: create customresourcedefinition/deliverables.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: create customresourcedefinition/workloads.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ---- waiting on 15 changes [0/22 done] ----
      10:48:37AM: ok: reconcile namespace/cartographer-system (v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clusterdeploymenttemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clusterdeliveries.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clusterimagetemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/workloads.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clustersourcetemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/pipelines.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clustersupplychains.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clusterruntemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clustertemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/clusterconfigtemplates.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile customresourcedefinition/deliverables.carto.run (apiextensions.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile clusterrolebinding/cartographer-cluster-admin (rbac.authorization.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile validatingwebhookconfiguration/deliveryvalidator (admissionregistration.k8s.io/v1) cluster
      10:48:37AM: ok: reconcile validatingwebhookconfiguration/clustersupplychainvalidator (admissionregistration.k8s.io/v1) cluster
      10:48:37AM: ---- applying 3 changes [15/22 done] ----
      10:48:37AM: create secret/private-registry-credentials (v1) namespace: cartographer-system
      10:48:37AM: create secret/cartographer-webhook (v1) namespace: cartographer-system
      10:48:37AM: create serviceaccount/cartographer-controller (v1) namespace: cartographer-system
      10:48:37AM: ---- waiting on 3 changes [15/22 done] ----
      10:48:37AM: ok: reconcile serviceaccount/cartographer-controller (v1) namespace: cartographer-system
      10:48:37AM: ok: reconcile secret/cartographer-webhook (v1) namespace: cartographer-system
      10:48:37AM: ok: reconcile secret/private-registry-credentials (v1) namespace: cartographer-system
      10:48:37AM: ---- applying 4 changes [18/22 done] ----
      10:48:37AM: create service/cartographer-webhook (v1) namespace: cartographer-system
      10:48:38AM: create deployment/cartographer-controller (apps/v1) namespace: cartographer-system
      10:48:39AM: create issuer/selfsigned-issuer (cert-manager.io/v1) namespace: cartographer-system
      10:48:39AM: create certificate/cartographer-webhook (cert-manager.io/v1) namespace: cartographer-system
      10:48:39AM: ---- waiting on 4 changes [18/22 done] ----
      10:48:39AM: ok: reconcile certificate/cartographer-webhook (cert-manager.io/v1) namespace: cartographer-system
      10:48:39AM: ok: reconcile issuer/selfsigned-issuer (cert-manager.io/v1) namespace: cartographer-system
      10:48:39AM: ok: reconcile service/cartographer-webhook (v1) namespace: cartographer-system
      10:48:40AM: ongoing: reconcile deployment/cartographer-controller (apps/v1) namespace: cartographer-system
      10:48:40AM:  ^ Waiting for 1 unavailable replicas
      10:48:40AM:  L ok: waiting on replicaset/cartographer-controller-6d4c59b495 (apps/v1) namespace: cartographer-system
      10:48:40AM:  L ongoing: waiting on pod/cartographer-controller-6d4c59b495-mfkdx (v1) namespace: cartographer-system
      10:48:40AM:     ^ Pending: ContainerCreating
      10:48:40AM: ---- waiting on 1 changes [21/22 done] ----
      10:48:41AM: ongoing: reconcile deployment/cartographer-controller (apps/v1) namespace: cartographer-system
      10:48:41AM:  ^ Waiting for 1 unavailable replicas
      10:48:41AM:  L ok: waiting on replicaset/cartographer-controller-6d4c59b495 (apps/v1) namespace: cartographer-system
      10:48:41AM:  L ok: waiting on pod/cartographer-controller-6d4c59b495-mfkdx (v1) namespace: cartographer-system
      10:48:42AM: ok: reconcile deployment/cartographer-controller (apps/v1) namespace: cartographer-system
      10:48:42AM: ---- applying complete [22/22 done] ----
      10:48:42AM: ---- waiting complete [22/22 done] ----
      Succeeded
    updatedAt: "2021-12-11T10:48:43Z"
  fetch:
    exitCode: 0
    startedAt: "2021-12-11T10:48:33Z"
    stdout: |
      apiVersion: vendir.k14s.io/v1alpha1
      directories:
      - contents:
        - imgpkgBundle:
            image: harbor-10-213-232-22.sslip.io/library/cartographer-bundle@sha256:35bfc11d92c14446863e251ad659a7232825212229d529a40d28c468c70392ec
          path: .
        path: "0"
      kind: LockConfig
    updatedAt: "2021-12-11T10:48:34Z"
  friendlyDescription: Reconcile succeeded
  inspect:
    exitCode: 0
    stdout: |-
      Target cluster 'https://100.64.0.1:443' (nodes: cheetah-control-plane-xtwcj, 1+)
      10:48:43AM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"networkpolicystats"}
      10:48:43AM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreaclusternetworkpolicystats"}
      10:48:43AM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreanetworkpolicystats"}
      Resources in app 'cartographer-ctrl'
      Namespace            Name                                      Kind                            Owner    Conds.  Rs  Ri  Age
      (cluster)            cartographer-cluster-admin                ClusterRoleBinding              kapp     -       ok  -   9s
      ^                    cartographer-system                       Namespace                       kapp     -       ok  -   9s
      ^                    clusterconfigtemplates.carto.run          CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clusterdeliveries.carto.run               CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clusterdeploymenttemplates.carto.run      CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clusterimagetemplates.carto.run           CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clusterruntemplates.carto.run             CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clustersourcetemplates.carto.run          CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clustersupplychains.carto.run             CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    clustersupplychainvalidator               ValidatingWebhookConfiguration  kapp     -       ok  -   8s
      ^                    clustertemplates.carto.run                CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    deliverables.carto.run                    CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    deliveryvalidator                         ValidatingWebhookConfiguration  kapp     -       ok  -   9s
      ^                    pipelines.carto.run                       CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      ^                    workloads.carto.run                       CustomResourceDefinition        kapp     2/2 t   ok  -   9s
      cartographer-system  cartographer-controller                   Deployment                      kapp     2/2 t   ok  -   7s
      ^                    cartographer-controller                   ServiceAccount                  kapp     -       ok  -   7s
      ^                    cartographer-controller-6d4c59b495        ReplicaSet                      cluster  -       ok  -   7s
      ^                    cartographer-controller-6d4c59b495-mfkdx  Pod                             cluster  4/4 t   ok  -   7s
      ^                    cartographer-webhook                      Certificate                     kapp     1/1 t   ok  -   7s
      ^                    cartographer-webhook                      Endpoints                       cluster  -       ok  -   7s
      ^                    cartographer-webhook                      Secret                          kapp     -       ok  -   7s
      ^                    cartographer-webhook                      Service                         kapp     -       ok  -   7s
      ^                    cartographer-webhook-8f7sc                CertificateRequest              cluster  1/1 t   ok  -   5s
      ^                    cartographer-webhook-d27zz                EndpointSlice                   cluster  -       ok  -   7s
      ^                    private-registry-credentials              Secret                          kapp     -       ok  -   7s
      ^                    selfsigned-issuer                         Issuer                          kapp     1/1 t   ok  -   7s
      Rs: Reconcile state
      Ri: Reconcile information
      27 resources
      Succeeded
    updatedAt: "2021-12-11T10:48:44Z"
  observedGeneration: 1
  template:
    exitCode: 0
    stderr: |
      resolve | final: projectcartographer/cartographer@sha256:a98ee8b044516aa54b5df264dc2a95d99281c2cac9ccd07657aa586a14a39dfa -> harbor-10-213-232-22.sslip.io/library/cartographer-bundle@sha256:a98ee8b044516aa54b5df264dc2a95d99281c2cac9ccd07657aa586a14a39dfa
    updatedAt: "2021-12-11T10:48:34Z"
```

---

今回紹介した既存クラスタの更新方法は、他の設定項目を変更したい場合にも使えるので覚えておくと役に立ちます。
ただしVSphereMachineTemplateリソースの変更 (例: [DNSの変更](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-tanzu-k8s-clusters-config-plans.html#nameserver)) 、immutableなリソースの設定を変更したいときには適用できないので注意が必要です。


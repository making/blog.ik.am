---
title: Tanzu Greenplum 7.7をVMware Fusion上のRocky Linux VMにインストールするメモ
tags: [ "Greenplum", "Tanzu", "PostgreSQL", "Rocky" ]
categories: [ "Middleware", "RDBMS", "Greenplum" ]
---

Tanzu Greenplumを検証するためにインストールする環境が欲しかったのですが、昨今、ラップトップもサーバーもARMにばかりしてしまい、
リソースに余裕があるx86_64環境が手元に無かったので、眠っていたIntel MacのVMware Fusion上にRocky Linux
VMを構築して、その上にTanzu Greenplumをインストールすることにしました。

## Rocky Linux VMの構築

今回は[Rocky Linux 9.7 Minimal ISO](https://download.rockylinux.org/pub/rocky/9/isos/x86_64/Rocky-9.7-x86_64-minimal.iso)
を使用しました。 https://download.rockylinux.org/pub/rocky/9/isos/x86_64/ からダウンロード可能です。

Coordinator 1台、Segment 3台の計4台構成を作ります。 まずはテンプレートとなるVMを1台作成し、そこからクローンして各サーバーを作成します。

IPアドレスは次のとおりにします。

| Host        | IP Address     |
|-------------|----------------|
| Coordinator | 192.168.11.200 |
| Segment1    | 192.168.11.201 |
| Segment2    | 192.168.11.202 |
| Segment3    | 192.168.11.203 |

ISOからVMを新規作成します。ここでは名前はgp-templateとしました。

各サーバー4vCPU、16GBメモリにします。(フル稼働しない前提でオーバーコミットします)

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/d8148ad4-868e-4300-b188-591d0b7fbc2c.png)

ディスク60GBにします

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/2784aba4-3d6e-48e0-abea-654fcb07b361.png)

ネットワークはブリッジで。

言語を選択。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/277ac084-7cea-4970-b336-495b533164c6.png)

必須項目を設定します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/b084596e-5ffc-49b5-902d-d07eea6d80f3.png)

ディスクを選択。デフォルトで。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/87c20433-882f-4816-83fe-0fa8c8c4a043.png)

IPアドレスはstaticに設定します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/989f3a9f-dd35-4a49-8453-4bf7c60b72b8.png)

rootのパスワードを設定します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/fe40be98-0d4b-41a7-9c9f-58c5453824b2.png)

"Begin Installation"をクリックしてインストール開始します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/99a96b4a-2d40-4420-9bb6-71fa65c800a8.png)

完了したら"Reboot System"をクリックして再起動します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/8d60ba47-277c-46a1-b2cb-6df4c7a0b6f7.png)

VMware Fusionのコンソールで作業を進めます。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/a9b274de-4c63-4d1a-a658-70178cafbe4c.png)

自分のSSH公開鍵を`~/.ssh/authorized_keys`に登録します。

```bash
curl https://github.com/making.keys > ~/.ssh/authorized_keys
```

ターミナルからsshでこのサーバーに接続します。

```bash
ssh root@192.168.11.200
```

Greenplumのインストールに必要なパッケージをインストールします。

```bash
sudo dnf -y install apr \
apr-util \
bash \
bzip2 \
curl \
iproute \
krb5-devel \
libcurl \
libevent \
libtiff \
libuuid \
libuv \
libxml2 \
libyaml \
libzstd \
lsof \
openldap \
openssh \
openssh-clients \
openssh-server \
openssl \
openssl-libs \
perl \
python3 \
python3-psycopg2 \
python3-psutil \
python3-pyyaml \
python3.11 \
python3.11-devel \
readline \
rsync \
sed \
tar \
which \
zip \
zlib \
sshpass \
java-21-openjdk-devel

echo 2 | sudo update-alternatives --config java

cat <<EOF | sudo tee -a /etc/sysctl.d/99-sysctl.conf > /dev/null
net.ipv4.ip_local_reserved_ports=65330
EOF
sudo sysctl --system

cat <<EOF | sudo tee -a /etc/security/limits.conf > /dev/null
* soft nofile 65536
* hard nofile 65536
EOF

```

必須ではないけれど、VMの監視用にNode Exporterもインストールしておきます。

```bash
sudo dnf install -y epel-release
sudo dnf install -y node-exporter
```

### Tanzu Greenplumのダウンロード

次に、GreenplumのRPMパッケージをダウンロードします。 Broadcomのアカウントが必要です。

一旦、サーバー上でDownloadsディレクトリを作成します。

```bash
mkdir -p ~/Downloads
```

[Broadcom Support](https://support.broadcom.com)にログインして、[Tanzu Greenplumのダウンロードページ](https://support.broadcom.com/group/ecx/productdownloads?subfamily=VMware%20Tanzu%20Greenplum)にアクセスします。

最新バージョンを選択します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/a2483369-ad05-4dd3-8d99-1c304e627ea6.png)

RHEL 9用のRPMパッケージをダウンロードします。必要に応じて他のパッケージもダウンロードしてください。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/e9678bd5-8d1e-4bd4-abf5-19166cc8fca7.png)

サーバーを抜けて、端末上で次のコマンドでダウンロードしたRPMパッケージをサーバーに転送します。

```bash
scp *.rpm root@192.168.11.200:~/Downloads/
```

### Tanzu Greenplumのインストール

サーバーに再度sshで接続します。

```bash
ssh root@192.168.11.200
```

gpadminユーザーを作ってダウンロードしたrpmをインストールします。

```bash
sudo groupadd gpadmin
sudo useradd -m gpadmin -g gpadmin
echo gpadmin:Greenplum123 | sudo chpasswd
echo 'gpadmin ALL=(ALL) NOPASSWD: ALL' | sudo EDITOR='tee -a' visudo

sudo yum -y install /root/Downloads/greenplum-db-7.7.0-el9-x86_64.rpm
sudo chown -R gpadmin:gpadmin /usr/local/greenplum*
sudo chown -R gpadmin:gpadmin /root/Downloads
sudo chgrp -R gpadmin /usr/local/greenplum*
```

Greenplum用の環境変数などが設定されたスクリプトを`.bashrc`で読み込むようにします。

```bash
cat <<EOF | sudo su - gpadmin bash -c 'tee -a /home/gpadmin/.bashrc'
source /usr/local/greenplum-db/greenplum_path.sh
EOF
```

Firewallを無効にします。

https://docs.vmware.com/en/VMware-Greenplum/7/greenplum-database/install_guide-prep_os.html#deactivate-or-configure-firewall-software-1

```bash
sudo systemctl stop firewalld.service
sudo systemctl disable firewalld.service
```

一旦サーバーをシャットダウンします。

```bash
sudo systemctl poweroff -i
```

### クローンの作成

VMware Fusionの管理画面で、先ほど作成したgp-template VMを右クリックして"フルクローンを作成"を選択します。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/0ccbbe1c-5d1a-461c-9f11-2a3e2559d469.png)

次の4 VMを作成し、それぞれ起動します。

* gp-coordinator
* gp-segment1
* gp-segment2
* gp-segment3

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/88ffae41-e16d-4724-b4ef-ce65a7b6727b.png)

各サーバーでホスト名とIPアドレスを設定します。クローン後はIPアドレスが重複しているので、VMware
Fusionのコンソール上で作業します。

gp-coordinatorはIPアドレスの変更は不要なので、ホスト名だけ変更します。

```bash
hostnamectl set-hostname gp-coordinator
```

gp-segment1~3は、次のコマンドでホスト名とIPアドレスを設定します。サーバー毎にホスト名とIPアドレスを変更してください。

```bash
hostnamectl set-hostname gp-segment1
nmcli connection show ens160
nmcli connection modify ens160 ipv4.addresses 192.168.11.201/24
nmcli connection down ens160
nmcli connection up ens160
ip addr
```

それぞれ次のような作業画面になります。

* gp-segment1
  ![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/8ace2cc1-b6e7-45a3-8118-1af280e2ad7a.png)
* gp-segment2
  ![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/e8ff11c3-16c2-4c25-aa0c-0dcdb0df1d23.png)
* gp-segment3
  ![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/f6b0b836-96f4-4a21-b597-1c523b20b02b.png)

設定が完了したら、各サーバーにsshで接続し、hostnameが正しく設定されていることを確認します。

```bash
$ for i in 200 201 202 203;do
ssh root@192.168.11.$i "hostname"
done
gp-coordinator
gp-segment1
gp-segment2
gp-segment3
```

次に、各サーバーの`/etc/hosts`ファイルを次の内容で更新します。

```bash
$ cat <<EOF > hosts 
192.168.11.200 gp-coordinator
192.168.11.201 gp-segment1
192.168.11.202 gp-segment2
192.168.11.203 gp-segment3
127.0.0.1 localhost
EOF
```

それぞれのサーバーに`/etc/hosts`ファイルをSCPで配布します。

```bash
for i in 200 201 202 203;do
scp hosts root@192.168.11.$i:/etc/hosts
done
```

### SSHの設定

各ノード間をパスワードレスでssh通信できるようにする必要があります。

```bash
for i in 200 201 202 203;do
ssh root@192.168.11.$i "su - gpadmin bash -c 'ssh-keygen -m PEM -t rsa -b 4096 -q -N \"\" -f /home/gpadmin/.ssh/id_rsa'"
done
```

以下はgp-coordinatorノード上で作業します。

```bash
ssh root@192.168.11.200
```

gp-coordinator の公開鍵を各ホストの `/home/gpadmin/.ssh/authorized_keys` に追記します。

```bash
sudo su - gpadmin
SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-coordinator
SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-segment1
SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-segment2
SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-segment3
```

次のコマンドで各ホストの公開鍵を各ホストの `/home/gpadmin/.ssh/known_hosts` に追記します。

```bash
cat <<EOF > hostfile_exkeys
gp-coordinator
gp-segment1
gp-segment2
gp-segment3
EOF

gpssh-exkeys -f hostfile_exkeys
```

### Tanzu Greenplumのセットアップ

次のセグメント構成でGreenplumクラスタをセットアップします。

| 項目            | 値                |
|---------------|------------------|
| セグメント数/サーバー   | 2                |
| 合計プライマリセグメント  | 6                |
| 合計ミラーセグメント    | 6                |
| 合計インスタンス/サーバー | 4（2プライマリ + 2ミラー） |


以下の作業は `gp-coordinator` 上でのみ行います。`gpadmin` ユーザーで作業します。

coordinatorのディレクトリを作成します。

```bash
sudo mkdir -p /data/coordinator
sudo chown gpadmin:gpadmin /data/coordinator
```

セグメントサーバーのホストファイルを作成します。

```bash
cat <<EOF > hostfile_gpssh_segonly
gp-segment1
gp-segment2
gp-segment3
EOF
```

各セグメントサーバーにディレクトリを作成します。

```bash
gpssh -f hostfile_gpssh_segonly -e 'sudo mkdir -p /data/primary'
gpssh -f hostfile_gpssh_segonly -e 'sudo mkdir -p /data/mirror'
gpssh -f hostfile_gpssh_segonly -e 'sudo chown -R gpadmin /data/*'
```

Greenplum初期化用の設定ファイルを準備します。

```bash
mkdir -p gpconfigs

cat <<EOF > gpconfigs/hostfile_gpinitsystem
gp-segment1
gp-segment2
gp-segment3
EOF
```

gpinitsystemの設定ファイルを作成します。

```bash
cp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/gpconfigs/gpinitsystem_config

sed -i.bak \
  -e 's|^declare -a DATA_DIRECTORY=.*|declare -a DATA_DIRECTORY=(/data/primary /data/primary)|' \
  -e 's|^#declare -a MIRROR_DATA_DIRECTORY=.*|declare -a MIRROR_DATA_DIRECTORY=(/data/mirror /data/mirror)|' \
  -e 's|^#MIRROR_PORT_BASE=.*|MIRROR_PORT_BASE=7000|' \
  -e 's|^COORDINATOR_HOSTNAME=.*|COORDINATOR_HOSTNAME=gp-coordinator|' \
  gpconfigs/gpinitsystem_config
```

**変更内容:**

- `DATA_DIRECTORY`: 各サーバーに2つのプライマリセグメント
- `MIRROR_DATA_DIRECTORY`: 各サーバーに2つのミラーセグメント
- `MIRROR_PORT_BASE`: ミラーのベースポート番号を有効化
- `COORDINATOR_HOSTNAME`: coordinatorホスト名を設定

sed後の設定ファイルを確認します。

```bash
grep -E "^(declare -a DATA_DIRECTORY|declare -a MIRROR_DATA_DIRECTORY|MIRROR_PORT_BASE|COORDINATOR_HOSTNAME|PORT_BASE)" gpconfigs/gpinitsystem_config
```

以下のように表示されることを確認します:

```bash
PORT_BASE=6000
declare -a DATA_DIRECTORY=(/data/primary /data/primary)
COORDINATOR_HOSTNAME=gp-coordinator
MIRROR_PORT_BASE=7000
declare -a MIRROR_DATA_DIRECTORY=(/data/mirror /data/mirror)
```

Greenplumクラスタを初期化します。

```bash
gpinitsystem -c gpconfigs/gpinitsystem_config -h gpconfigs/hostfile_gpinitsystem
```

初期化時に確認メッセージが表示されたら `y` を入力してください。

```bash
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking configuration parameters, please wait...
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Reading Greenplum configuration file gpconfigs/gpinitsystem_config
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Locale has not been set in gpconfigs/gpinitsystem_config, will set to default value
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-No DATABASE_NAME set, will exit following template1 updates
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-COORDINATOR_MAX_CONNECT not set, will set to default value 250
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking configuration parameters, Completed
20251212:20:45:29:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing multi-home checks, please wait...
...
20251212:20:45:30:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Configuring build for standard array
20251212:20:45:30:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing multi-home checks, Completed
20251212:20:45:30:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Building primary segment instance array, please wait...
......
20251212:20:45:33:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Building group mirror array type , please wait...
......
20251212:20:45:36:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking Coordinator host
20251212:20:45:36:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking new segment hosts, please wait...
............
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking new segment hosts, Completed
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Database Creation Parameters
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator Configuration
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator hostname       = gp-coordinator
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator port           = 5432
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator instance dir   = /data/coordinator/gpseg-1
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator LOCALE         = 
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum segment prefix   = gpseg
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator Database       = 
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator connections    = 250
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator buffers        = 128000kB
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Segment connections        = 750
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Segment buffers            = 128000kB
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Encoding                   = UNICODE
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Postgres param file        = Off
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Initdb to be used          = /usr/local/greenplum-db-7.7.0/bin/initdb
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-GP_LIBRARY_PATH is         = /usr/local/greenplum-db-7.7.0/lib
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-HEAP_CHECKSUM is           = on
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-HBA_HOSTNAMES is           = 0
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Ulimit check               = Passed
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Array host connect type    = Single hostname per node
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [1]      = ::1
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [2]      = 192.168.11.200
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [3]      = 192.168.11.69
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [4]      = fe80::20c:29ff:fe61:b08
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Standby Coordinator             = Not Configured
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Number of primary segments = 2
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total Database segments    = 6
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Trusted shell              = ssh
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Number segment hosts       = 3
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Mirror port base           = 7000
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Number of mirror segments  = 2
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Mirroring config           = ON
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Mirroring type             = Group
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:----------------------------------------
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Primary Segment Configuration
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:----------------------------------------
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment1 	6000 	gp-segment1 	/data/primary/gpseg0 	2
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment1 	6001 	gp-segment1 	/data/primary/gpseg1 	3
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment2 	6000 	gp-segment2 	/data/primary/gpseg2 	4
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment2 	6001 	gp-segment2 	/data/primary/gpseg3 	5
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment3 	6000 	gp-segment3 	/data/primary/gpseg4 	6
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment3 	6001 	gp-segment3 	/data/primary/gpseg5 	7
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Mirror Segment Configuration
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment2 	7000 	gp-segment2 	/data/mirror/gpseg0 	8
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment2 	7001 	gp-segment2 	/data/mirror/gpseg1 	9
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment3 	7000 	gp-segment3 	/data/mirror/gpseg2 	10
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment3 	7001 	gp-segment3 	/data/mirror/gpseg3 	11
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment1 	7000 	gp-segment1 	/data/mirror/gpseg4 	12
20251212:20:45:49:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment1 	7001 	gp-segment1 	/data/mirror/gpseg5 	13

Continue with Greenplum creation Yy|Nn (default=N):
> 
```

yを入力すると、次のようなログが出力されます。



```bash
20251212:20:47:18:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Building the Coordinator instance database, please wait...
20251212:20:47:30:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Starting the Coordinator in admin mode
20251212:20:47:31:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing parallel build of primary segment instances
20251212:20:47:31:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Spawning parallel processes    batch [1], please wait...
......
20251212:20:47:31:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Waiting for parallel processes batch [1], please wait...
..................................................
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Parallel process exit status
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as completed           = 6
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as killed              = 0
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as failed              = 0
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Removing back out file
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-No errors generated from parallel processes
20251212:20:48:21:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Restarting the Greenplum instance in production mode
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Starting gpstop with args: -a -l /home/gpadmin/gpAdminLogs -m -d /data/coordinator/gpseg-1
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Gathering information and validating the environment...
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Obtaining Greenplum Coordinator catalog information
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Obtaining Segment details from coordinator...
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Greenplum Version: 'postgres (Greenplum Database) 7.7.0 build commit:e7e9f681dc799e69563184bd154b910b54eb18f4'
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Commencing Coordinator instance shutdown with mode='smart'
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Coordinator segment instance directory=/data/coordinator/gpseg-1
20251212:20:48:21:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Stopping coordinator segment and waiting for user connections to finish ...
server shutting down
20251212:20:48:22:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Attempting forceful termination of any leftover coordinator process
20251212:20:48:22:008979 gpstop:gp-coordinator:gpadmin-[INFO]:-Terminating processes for segment /data/coordinator/gpseg-1
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Starting gpstart with args: -a -l /home/gpadmin/gpAdminLogs -d /data/coordinator/gpseg-1
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Gathering information and validating the environment...
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Greenplum Binary Version: 'postgres (Greenplum Database) 7.7.0 build commit:e7e9f681dc799e69563184bd154b910b54eb18f4'
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Greenplum Catalog Version: '302307241'
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Starting Coordinator instance in admin mode
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-CoordinatorStart pg_ctl cmd is env GPSESSID=0000000000 GPERA=None COORDINATOR_DATA_DIRECTORY=/data/coordinator/gpseg-1 $GPHOME/bin/pg_ctl -D /data/coordinator/gpseg-1 -l /data/coordinator/gpseg-1/log/startup.log -w -t 600 -o " -c gp_role=utility " start
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Obtaining Greenplum Coordinator catalog information
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Obtaining Segment details from coordinator...
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Setting new coordinator era
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Coordinator Started...
20251212:20:48:23:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Shutting down coordinator
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Commencing parallel segment instance startup, please wait...
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Process results...
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-   Successful segment starts                                            = 6
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-   Failed segment starts                                                = 0
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-   Skipped segment starts (segments are marked down in configuration)   = 0
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Successfully started 6 of 6 segment instances 
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Starting Coordinator instance gp-coordinator directory /data/coordinator/gpseg-1 
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-CoordinatorStart pg_ctl cmd is env GPSESSID=0000000000 GPERA=ab03d3b04e6ea60f_251212204823 COORDINATOR_DATA_DIRECTORY=/data/coordinator/gpseg-1 $GPHOME/bin/pg_ctl -D /data/coordinator/gpseg-1 -l /data/coordinator/gpseg-1/log/startup.log -w -t 600 -o " -c gp_role=dispatch " start
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Command pg_ctl reports Coordinator gp-coordinator instance active
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Connecting to db template1 on host localhost
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-No standby coordinator configured.  skipping...
20251212:20:48:24:009043 gpstart:gp-coordinator:gpadmin-[INFO]:-Database successfully started
20251212:20:48:24:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Completed restart of Greenplum instance in production mode
20251212:20:48:24:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Creating core GPDB extensions
20251212:20:48:25:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Importing system collations
20251212:20:48:32:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing parallel build of mirror segment instances
20251212:20:48:32:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Spawning parallel processes    batch [1], please wait...
......
20251212:20:48:32:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Waiting for parallel processes batch [1], please wait...
.........
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Parallel process exit status
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as completed           = 6
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as killed              = 0
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as failed              = 0
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Scanning utility log file for any warning messages
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Log file scan check passed
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Database instance successfully created
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-------------------------------------------------------
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-To complete the environment configuration, please 
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-update gpadmin .bashrc file with the following
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-1. Ensure that the greenplum_path.sh file is sourced
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-2. Add "export COORDINATOR_DATA_DIRECTORY=/data/coordinator/gpseg-1"
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-   to access the Greenplum scripts for this instance:
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-   or, use -d /data/coordinator/gpseg-1 option for the Greenplum scripts
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-   Example gpstate -d /data/coordinator/gpseg-1
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Script log file = /home/gpadmin/gpAdminLogs/gpinitsystem_20251212.log
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-To remove instance, run gpdeletesystem utility
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-To initialize a Standby Coordinator Segment for this Greenplum instance
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Review options for gpinitstandby
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-------------------------------------------------------
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-The Coordinator /data/coordinator/gpseg-1/pg_hba.conf post gpinitsystem
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-has been configured to allow all hosts within this new
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-array to intercommunicate. Any hosts external to this
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-new array must be explicitly added to this file
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Refer to the Greenplum Admin support guide which is
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-located in the /usr/local/greenplum-db-7.7.0/docs directory
20251212:20:48:41:002425 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-------------------------------------------------------
```

"Successfully started 6 of 6 segment instances" と出力されたのでセットアップが成功しました。

`.barshrc`に次の環境変数を追加します。

```bash
cat <<EOF | tee -a /home/gpadmin/.bashrc > /dev/null
export COORDINATOR_DATA_DIRECTORY=/data/coordinator/gpseg-1
export PGPORT=5432
export PGUSER=gpadmin
export PGDATABASE=gpadmin
export LD_PRELOAD=/lib64/libz.so.1 ps
EOF

source /home/gpadmin/.bashrc
```

### 構成の確認

```bash
# 環境変数の読み込み（まだの場合）
source /usr/local/greenplum-db/greenplum_path.sh

# クラスタ状態確認
gpstate -s

# セグメント詳細確認
gpstate -e

# ミラー状態確認
gpstate -m
```

セグメント詳細確認は次のように表示されます:

```bash
$ gpstate -e
20251212:20:50:27:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-Starting gpstate with args: -e
20251212:20:50:27:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-local Greenplum Version: 'postgres (Greenplum Database) 7.7.0 build commit:e7e9f681dc799e69563184bd154b910b54eb18f4'
20251212:20:50:27:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-Coordinator Greenplum Version: 'PostgreSQL 12.22 (Greenplum Database 7.7.0 build commit:e7e9f681dc799e69563184bd154b910b54eb18f4) on x86_64-pc-linux-gnu, compiled by gcc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-11), 64-bit compiled on Dec  7 2025 05:50:22 Bhuvnesh C.'
20251212:20:50:27:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-Obtaining Segment details from coordinator...
20251212:20:50:27:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-Gathering data from segments...
20251212:20:50:28:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20251212:20:50:28:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-Segment Mirroring Status Report
20251212:20:50:28:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20251212:20:50:28:011663 gpstate:gp-coordinator:gpadmin-[INFO]:-All segments are running normally
```

ミラー状態確認は次のように表示されます:

```bash
$ gpstate -m
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-Starting gpstate with args: -m
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-local Greenplum Version: 'postgres (Greenplum Database) 7.7.0 build commit:e7e9f681dc799e69563184bd154b910b54eb18f4'
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-Coordinator Greenplum Version: 'PostgreSQL 12.22 (Greenplum Database 7.7.0 build commit:e7e9f681dc799e69563184bd154b910b54eb18f4) on x86_64-pc-linux-gnu, compiled by gcc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-11), 64-bit compiled on Dec  7 2025 05:50:22 Bhuvnesh C.'
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-Obtaining Segment details from coordinator...
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:--------------------------------------------------------------
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:--Current GPDB mirror list and status
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:--Type = Group
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:--------------------------------------------------------------
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   Mirror        Datadir               Port   Status    Data Status    
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   gp-segment2   /data/mirror/gpseg0   7000   Passive   Synchronized
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   gp-segment2   /data/mirror/gpseg1   7001   Passive   Synchronized
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   gp-segment3   /data/mirror/gpseg2   7000   Passive   Synchronized
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   gp-segment3   /data/mirror/gpseg3   7001   Passive   Synchronized
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   gp-segment1   /data/mirror/gpseg4   7000   Passive   Synchronized
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:-   gp-segment1   /data/mirror/gpseg5   7001   Passive   Synchronized
20251212:20:50:43:011700 gpstate:gp-coordinator:gpadmin-[INFO]:--------------------------------------------------------------
```

`psql`でも構成を確認します。

```bash
psql -d postgres -c "SELECT content, role, preferred_role, hostname, port, datadir, status FROM gp_segment_configuration ORDER BY content, role;"
```

以下の構成になっていることを確認します:

```
 content | role | preferred_role |    hostname    | port |          datadir          | status 
---------+------+----------------+----------------+------+---------------------------+--------
      -1 | p    | p              | gp-coordinator | 5432 | /data/coordinator/gpseg-1 | u
       0 | m    | m              | gp-segment2    | 7000 | /data/mirror/gpseg0       | u
       0 | p    | p              | gp-segment1    | 6000 | /data/primary/gpseg0      | u
       1 | m    | m              | gp-segment2    | 7001 | /data/mirror/gpseg1       | u
       1 | p    | p              | gp-segment1    | 6001 | /data/primary/gpseg1      | u
       2 | m    | m              | gp-segment3    | 7000 | /data/mirror/gpseg2       | u
       2 | p    | p              | gp-segment2    | 6000 | /data/primary/gpseg2      | u
       3 | m    | m              | gp-segment3    | 7001 | /data/mirror/gpseg3       | u
       3 | p    | p              | gp-segment2    | 6001 | /data/primary/gpseg3      | u
       4 | m    | m              | gp-segment1    | 7000 | /data/mirror/gpseg4       | u
       4 | p    | p              | gp-segment3    | 6000 | /data/primary/gpseg4      | u
       5 | m    | m              | gp-segment1    | 7001 | /data/mirror/gpseg5       | u
       5 | p    | p              | gp-segment3    | 6001 | /data/primary/gpseg5      | u
(13 rows)
```

**構成のポイント:**

- 合計6つのプライマリセグメント（content 0-5）
- 各プライマリに対応するミラーが別ホストに配置
- 各サーバーに2プライマリ + 2ミラー = 計4インスタンス

### 動作確認

テストデータベースを作成します。

```bash
createdb test
```

テーブルを作成し、動作確認します。

```bash
psql -d test -c "CREATE TABLE test_table (id int, name text) DISTRIBUTED BY (id);"
psql -d test -c "INSERT INTO test_table SELECT generate_series(1,1000), 'test_data';"
psql -d test -c "SELECT gp_segment_id, count(*) FROM test_table GROUP BY gp_segment_id ORDER BY gp_segment_id;"
```

次のように6つのセグメント（0-5）にデータが分散されていることを確認してください。

```
 gp_segment_id | count 
---------------+-------
             0 |   172
             1 |   163
             2 |   182
             3 |   164
             4 |   168
             5 |   151
(6 rows)
```

### トラブルシューティング

#### 初期化に失敗した場合

```bash
# クリーンアップ
gpdeletesystem -d /data/coordinator/gpsne-1 -f

# ディレクトリを削除して再作成
gpssh -f hostfile_gpssh_segonly -e 'sudo rm -rf /data/primary/*'
gpssh -f hostfile_gpssh_segonly -e 'sudo rm -rf /data/mirror/*'
sudo rm -rf /data/coordinator/*

# 手順5から再実行
```

#### ミラーが同期しない場合

```bash
# 再同期実行
gprecoverseg

# それでも同期しない場合はフル再同期
gprecoverseg -F
```

#### sedの置換が正しくできているか確認

```bash
# バックアップファイルとの差分確認
diff gpconfigs/gpinitsystem_config.bak gpconfigs/gpinitsystem_config
```

---

以上でセットアップ完了です。
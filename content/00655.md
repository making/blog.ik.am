---
title: VMware Tanzu SQL with Postgres for Kubernetes 1.2をインストールしてSpring Bootアプリからアクセスするメモ
tags: ["Kubernetes", "Tanzu", "PostgreSQL", "Spring Boot"]
categories: ["Dev", "CaaS", "Kubernetes", "TanzuSQL", "PostgreSQL"]
---

[VMware Tanzu SQL with Postgres for Kubernetes 1.2.0](https://postgres-kubernetes.docs.pivotal.io/1-2/release-notes.html) (以下、Tanzu Postgres) がリリースされ、
ようやく`default` namespace以外にPostgres Operatorをインストールできるようになったので試します。

cert-manager 1.0以上のインストールが必須で、TKG Extensionに含まれている古いバージョンと合わないので、TKGではなくkindを使って試します。

**目次**
<!-- toc -->

### 事前準備

Kindでクラスタを作成します。

```
kind create cluster
```

cert-managerをインストールします。

```
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.4.1/cert-manager.yaml
```

### Tanzu Postgres Operatorのインストール

Tanzu PostgresのメインであるTanzu Postgres OperatorはHelm 3でインストールできます。

Tanzu Network Registryにログインします。

```
export TANZUNET_USERNAME=...
export TANZUNET_PASSWORD=...
export HELM_EXPERIMENTAL_OCI=1

helm registry login registry.pivotal.io \
       --username=${TANZUNET_USERNAME} \
       --password=${TANZUNET_PASSWORD}
```

Helm chartをローカルに展開します。

```
helm chart pull registry.pivotal.io/tanzu-sql-postgres/postgres-operator-chart:v1.2.0
helm chart export registry.pivotal.io/tanzu-sql-postgres/postgres-operator-chart:v1.2.0 --destination=/tmp/
```

Tanzu Network RegistryへのimagePullSecretを作成します。今回は `postgres-operator` namespaceにTanzu Postgres Operatorをインストールします。

```
kubectl create namespace postgres-operator
kubectl create secret docker-registry regsecret \
    -n postgres-operator \
    --docker-server=https://registry.pivotal.io/ \
    --docker-username=${TANZUNET_USERNAME} \
    --docker-password=${TANZUNET_PASSWORD} \
    --dry-run=client \
    -o yaml \
    | kubectl apply -f-
```

展開したチャートをインストールします。

```
helm install -n postgres-operator --wait postgres-operator /tmp/postgres-operator/
```

しばらくするとインストールが完了します。次のコマンドでリソースを確認します。

```
$ kubectl get pod,service,certificate,clusterissuer -n postgres-operator 
NAME                                     READY   STATUS    RESTARTS   AGE
pod/postgres-operator-698b445bc4-wxl7n   1/1     Running   0          2m5s

NAME                                        TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
service/postgres-operator-webhook-service   ClusterIP   10.96.69.232   <none>        443/TCP   2m5s

NAME                                                         READY   SECRET                                  AGE
certificate.cert-manager.io/postgres-operator-serving-cert   True    postgres-operator-webhook-server-cert   2m5s

NAME                                                                            READY   AGE
clusterissuer.cert-manager.io/postgres-operator-ca-certificate-cluster-issuer   True    2m5s
clusterissuer.cert-manager.io/postgres-operator-selfsigned-clusterissuer        True    2m5s
```

またPostgres Custom Resourceが利用できるようになります。

```
$ kubectl api-resources --api-group sql.tanzu.vmware.com
NAME       SHORTNAMES   APIVERSION                NAMESPACED   KIND
postgres   pg           sql.tanzu.vmware.com/v1   true         Postgres
```

### Postgres Instanceの作成

早速Postgresリソースを作成します。今回はdefault namespaceに作成します。

imagePullSecretをdefault namespaceにも作成します。

```yaml
kubectl create secret docker-registry regsecret \
  -n default \
  --docker-server=https://registry.pivotal.io/ \
  --docker-username=${TANZUNET_USERNAME} \
  --docker-password=${TANZUNET_PASSWORD} \
  --dry-run=client \
  -o yaml \
  | kubectl apply -f-
```

次に`vehicle-db`という名前のPostgresリソースを作成します。

```
cat <<EOF | kubectl apply -f-
apiVersion: sql.tanzu.vmware.com/v1
kind: Postgres
metadata:
  name: vehicle-db
  namespace: default
spec:
  storageClassName: standard
  storageSize: 800M
  cpu: "0.8"
  memory: 800Mi
  monitorStorageClassName: standard
  monitorStorageSize: 1G
  resources:
    monitor:
      limits:
        cpu: 800m
        memory: 800Mi
      requests:
        cpu: 800m
        memory: 800Mi
  pgConfig:
    dbname: vehicle-db
    username: pgadmin
  serviceType: ClusterIP
  highAvailability:
    enabled: true
EOF
```

次のコマンドで作成されたリソースを確認します。PostgreSQLのStatefulSetが作成されています。

```
$ kubectl get all,pvc,certificate,secret -l postgres-instance=vehicle-db
NAME                       READY   STATUS    RESTARTS   AGE
pod/vehicle-db-0           3/3     Running   0          118s
pod/vehicle-db-1           3/3     Running   0          118s
pod/vehicle-db-monitor-0   4/4     Running   0          2m49s

NAME                       TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE
service/vehicle-db         ClusterIP   10.96.197.3   <none>        5432/TCP   2m49s
service/vehicle-db-agent   ClusterIP   None          <none>        <none>     2m49s

NAME                                  READY   AGE
statefulset.apps/vehicle-db           2/2     118s
statefulset.apps/vehicle-db-monitor   1/1     2m49s

NAME                                       STATUS    AGE
postgres.sql.tanzu.vmware.com/vehicle-db   Running   2m50s

NAME                                                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/vehicle-db-monitor-vehicle-db-monitor-0   Bound    pvc-71d7b651-a1d3-4579-a9fb-e88fd7f75451   1G         RWO            standard       2m50s
persistentvolumeclaim/vehicle-db-pgdata-vehicle-db-0            Bound    pvc-183816fb-9a5e-458e-978c-0b29ba77c249   800M       RWO            standard       119s
persistentvolumeclaim/vehicle-db-pgdata-vehicle-db-1            Bound    pvc-8feeec92-3576-4935-b2fe-e7e4ba4550b3   800M       RWO            standard       119s

NAME                                                              READY   SECRET                           AGE
certificate.cert-manager.io/vehicle-db-internal-ssl-certificate   True    vehicle-db-internal-ssl-secret   2m50s

NAME                                    TYPE                DATA   AGE
secret/vehicle-db-db-secret             Opaque              5      2m50s
secret/vehicle-db-empty-secret          Opaque              0      2m50s
secret/vehicle-db-internal-ssl-secret   kubernetes.io/tls   3      2m50s
secret/vehicle-db-monitor-secret        Opaque              3      2m50s
secret/vehicle-db-pgbackrest-secret     Opaque              3      2m50s
```

[HA構成](https://postgres-kubernetes.docs.pivotal.io/1-2/high-availability.html) を有効にしてあるので、次の図のようにprimaryとmirrorのPostgres及びmonitorのPodが立ち上がります。

![](https://postgres-kubernetes.docs.pivotal.io/1-2/images/postgres_ha.png)

Postgres Podのラベルを確認するとどちらかがprimary(`role=read-write`)でどちらがmirror(`role=read`)かがわかります。

```
$ kubectl get pod -l postgres-instance=vehicle-db,type=data --show-labels
NAME           READY   STATUS    RESTARTS   AGE   LABELS
vehicle-db-0   3/3     Running   0          70m   app=postgres,controller-revision-hash=vehicle-db-7cd7587b76,headless-service=vehicle-db,postgres-instance=vehicle-db,role=read-write,statefulset.kubernetes.io/pod-name=vehicle-db-0,type=data
vehicle-db-1   3/3     Running   0          70m   app=postgres,controller-revision-hash=vehicle-db-7cd7587b76,headless-service=vehicle-db,postgres-instance=vehicle-db,role=read,statefulset.kubernetes.io/pod-name=vehicle-db-1,type=data
```

Serviceは2つ作成されており、FQDN `vehicle-db.default.svc.cluster.local`へのリクエストは`role=read-write`ラベルがついているPodへルーティングされ、
`vehicle-db-0.vehicle-db-agent.default.svc.cluster.local`と`vehicle-db-1.vehicle-db-agent.default.svc.cluster.local`はHeadless Serviceで個々のPodへ直接ルーティングされます。

```
$ kubectl get svc -l postgres-instance=vehicle-db -owide 
NAME               TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE   SELECTOR
vehicle-db         ClusterIP   10.96.196.90   <none>        5432/TCP   71m   app=postgres,postgres-instance=vehicle-db,role=read-write,type=data
vehicle-db-agent   ClusterIP   None           <none>        <none>     71m   headless-service=vehicle-db
```

次のコマンドで各ノードの状態を見ることができます。node_1がprimary、node_2がsecondaryになっています。

```
$ kubectl exec -ti pod/vehicle-db-1 -- pg_autoctl show state
Defaulting container name to pg-container.
Use 'kubectl describe pod/vehicle-db-1 -n default' to see all of the containers in this pod.
  Name |  Node |                                                    Host:Port |       LSN | Reachable |       Current State |      Assigned State
-------+-------+--------------------------------------------------------------+-----------+-----------+---------------------+--------------------
node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 | 0/D0244B8 |       yes |             primary |             primary
node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 | 0/D0244B8 |       yes |           secondary |           secondary
```

次のようにPod上でpsqlを実行できます。

```
$ kubectl exec -it vehicle-db-1 -- bash -c 'psql -c "\l"'          
Defaulting container name to pg-container.
Use 'kubectl describe pod/vehicle-db-1 -n default' to see all of the containers in this pod.
                              List of databases
    Name    |  Owner   | Encoding | Collate |  Ctype  |   Access privileges   
------------+----------+----------+---------+---------+-----------------------
 postgres   | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 template0  | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
            |          |          |         |         | postgres=CTc/postgres
 template1  | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
            |          |          |         |         | postgres=CTc/postgres
 vehicle-db | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
(4 rows)
```

### failoverの動作確認

failover時の動作を確認します。次のコマンドでfailoverを起こせます。

```
$ kubectl exec -ti pod/vehicle-db-1 -- pg_autoctl perform failover
Defaulting container name to pg-container.
Use 'kubectl describe pod/vehicle-db-1 -n default' to see all of the containers in this pod.
05:35:30 11534 INFO  Targetting group 0 in formation "default"
05:35:30 11534 INFO  Listening monitor notifications about state changes in formation "default" and group 0
05:35:30 11534 INFO  Following table displays times when notifications are received
    Time |   Name |  Node |                                                    Host:Port |       Current State |      Assigned State
---------+--------+-------+--------------------------------------------------------------+---------------------+--------------------
05:35:30 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |             primary |            draining
05:35:30 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |           secondary |   prepare_promotion
05:35:30 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |   prepare_promotion |   prepare_promotion
05:35:30 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |   prepare_promotion |    stop_replication
05:35:30 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |             primary |      demote_timeout
05:35:30 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |            draining |      demote_timeout
05:35:30 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |      demote_timeout |      demote_timeout
05:35:31 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |    stop_replication |    stop_replication
05:35:31 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |    stop_replication |        wait_primary
05:35:31 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |      demote_timeout |             demoted
05:35:31 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |             demoted |             demoted
05:35:31 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |        wait_primary |        wait_primary
05:35:31 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |             demoted |          catchingup
05:35:52 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |          catchingup |          catchingup
05:35:53 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |          catchingup |           secondary
05:35:53 | node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 |           secondary |           secondary
05:35:54 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |        wait_primary |             primary
05:35:54 | node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 |             primary |             primary

$ kubectl exec -ti pod/vehicle-db-1 -- pg_autoctl show state
Defaulting container name to pg-container.
Use 'kubectl describe pod/vehicle-db-1 -n default' to see all of the containers in this pod.
  Name |  Node |                                                    Host:Port |       LSN | Reachable |       Current State |      Assigned State
-------+-------+--------------------------------------------------------------+-----------+-----------+---------------------+--------------------
node_1 |     1 | vehicle-db-0.vehicle-db-agent.default.svc.cluster.local:5432 | 0/F000610 |       yes |           secondary |           secondary
node_2 |     2 | vehicle-db-1.vehicle-db-agent.default.svc.cluster.local:5432 | 0/F000610 |       yes |             primary |             primary
```

Stateの変更が逐次出力され、primaryだったnode_1がsecondaryに、secondaryだったnode_2がprimaryに切り替わったことがわかります。


failover中はPodのラベルが次のように変わります。

```
$ kubectl get pod -l postgres-instance=vehicle-db,type=data --show-labels -w
NAME           READY   STATUS    RESTARTS   AGE     LABELS
vehicle-db-0   3/3     Running   0          3m16s   app=postgres,controller-revision-hash=vehicle-db-7c5bbd4d77,headless-service=vehicle-db,postgres-instance=vehicle-db,role=read-write,statefulset.kubernetes.io/pod-name=vehicle-db-0,type=data
vehicle-db-1   3/3     Running   0          3m26s   app=postgres,controller-revision-hash=vehicle-db-7c5bbd4d77,headless-service=vehicle-db,postgres-instance=vehicle-db,role=read,statefulset.kubernetes.io/pod-name=vehicle-db-1,type=data
vehicle-db-0   3/3     Running   0          3m19s   app=postgres,controller-revision-hash=vehicle-db-7c5bbd4d77,headless-service=vehicle-db,postgres-instance=vehicle-db,role=unavailable,statefulset.kubernetes.io/pod-name=vehicle-db-0,type=data
vehicle-db-1   3/3     Running   0          3m29s   app=postgres,controller-revision-hash=vehicle-db-7c5bbd4d77,headless-service=vehicle-db,postgres-instance=vehicle-db,role=unavailable,statefulset.kubernetes.io/pod-name=vehicle-db-1,type=data
vehicle-db-1   3/3     Running   0          3m30s   app=postgres,controller-revision-hash=vehicle-db-7c5bbd4d77,headless-service=vehicle-db,postgres-instance=vehicle-db,role=read-write,statefulset.kubernetes.io/pod-name=vehicle-db-1,type=data
vehicle-db-0   3/3     Running   0          3m42s   app=postgres,controller-revision-hash=vehicle-db-7c5bbd4d77,headless-service=vehicle-db,postgres-instance=vehicle-db,role=read,statefulset.kubernetes.io/pod-name=vehicle-db-0,type=data
```

### Spring Bootアプリから作成したPostgres Instanceへアクセス

`vehicle-db`へアクセスする`vehicle-api`アプリをデプロイします。
アプリケーションのDocker Imageは [`ghcr.io/making/vehicle-api`](https://github.com/users/making/packages/container/package/vehicle-api) です。
> `vehicle-api`のソースコードとDocker Imageの作成方法は [Spring Boot and Cloud Native Buildpacks Hands-on Lab](https://spring-boot-cnb-hol.apps.pcfone.io/#2) の"3. Getting Started"を参照してください。


`vehicle-db-db-secret`という名前のSecretに`vehicle-db`の認証情報が格納されています。
項目は次の通りです。

```
$ kubectl describe secret vehicle-db-db-secret 
Name:         vehicle-db-db-secret
Namespace:    default
Labels:       app=postgres
              postgres-instance=vehicle-db
Annotations:  <none>

Type:  Opaque

Data
====
username:      7 bytes
dbname:        10 bytes
instancename:  10 bytes
namespace:     7 bytes
password:      30 bytes
```

[Config Tree](/entries/626)を使って`vehicle-db-db-secret`の各項目が`spring.datasource.`以下にバインドされるように次のmanifestをデプロイします。
URLはHeadlessではない`vehicle-db`を使用します。

```yaml
cat <<'EOF' > /tmp/vehicle-api.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: vehicle-api
  name: vehicle-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vehicle-api
  template:
    metadata:
      labels:
        app: vehicle-api
    spec:
      containers:
      - image: ghcr.io/making/vehicle-api
        name: vehicle-api
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_CONFIG_IMPORT
          value: configtree:/workspace/config/
        - name: SPRING_DATASOURCE_URL
          value: jdbc:postgresql://vehicle-db.${spring.datasource.namespace}.svc.cluster.local:5432/${spring.datasource.dbname}
        - name: MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE
          value: health,info
        #! Tweak for less memory 
        - name: SPRING_DATASOURCE_HIKARI_MAXIMUMPOOLSIZE
          value: "4"
        - name: JAVA_TOOL_OPTIONS
          value: -XX:ReservedCodeCacheSize=32M -Xss512k -Duser.timezone=Asia/Tokyo
        - name: BPL_JVM_THREAD_COUNT
          value: "20"
        - name: SERVER_TOMCAT_THREADS_MAX
          value: "4"
        resources:
          limits:
            memory: 256Mi
          requests:
            memory: 256Mi
        volumeMounts:
        - name: vehicle-db
          mountPath: /workspace/config/spring/datasource
          readOnly: true
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
            scheme: HTTP
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
            scheme: HTTP
      volumes:
      - name: vehicle-db
        secret:
          secretName: vehicle-db-db-secret
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: vehicle-api
  name: vehicle-api
spec:
  ports:
  - name: http
    port: 80
    targetPort: 8080
  selector:
    app: vehicle-api
EOF
kubectl apply -f /tmp/vehicle-api.yaml
```

デプロイできたら、[kwt](/entries/649)を使ってアクセスします。


別のターミナル上で次のコマンドを実行します。
```
sudo -E kwt net start
```

> `kwt`が使えない場合は、代わりに次のコマンドを実行し、
> 
> ```
> kubectl port-forward service/vehicle-api 8080:80
> ```
> 
> 以下の`vehicle-api.default.svc.cluster.local`を`localhost:8080`に変更してください。

次のコマンドでvehicle-apiにアクセスします。

```
$ curl -s http://vehicle-api.default.svc.cluster.local/vehicles | jq .
[
  {
    "id": 1,
    "name": "Avalon"
  },
  {
    "id": 2,
    "name": "Corolla"
  },
  {
    "id": 3,
    "name": "Crown"
  },
  {
    "id": 4,
    "name": "Levin"
  },
  {
    "id": 5,
    "name": "Yaris"
  },
  {
    "id": 6,
    "name": "Vios"
  },
  {
    "id": 7,
    "name": "Glanza"
  },
  {
    "id": 8,
    "name": "Aygo"
  }
]
```


> ここではprimaryへのアクセスはKubernetesのServiceの機能に任せましたが、JDBC Driver側に任せることもできます。
> この場合はHeadless Serviceの`vehicle-db-agent`を使用します。設定方法の詳細は次のドキュメントが参考になります。
> 
> * https://jdbc.postgresql.org/documentation/head/connect.html
> * https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.BestPractices.html
> 
> まずsecondary(read)への接続を試行し、接続できない場合は、primary(read0write)に接続されるようにしたい場合の設定は次の通りです。
> 
> ```yaml
>         - name: SPRING_DATASOURCE_URL
>           value: jdbc:postgresql://vehicle-db-0.vehicle-db-agent.${spring.datasource.namespace}.svc.cluster.local:5432,vehicle-db-1.vehicle-db-agent.${spring.datasource.namespace}.svc.cluster.local:5432/${spring.datasource.dbname}
>         - name: SPRING_DATASOURCE_HIKARI_DATASOURCEPROPERTIES_TARGETSERVERTYPE
>           value: preferSecondary
>         - name: SPRING_DATASOURCE_HIKARI_DATASOURCEPROPERTIES_LOADBALANCEHOSTS
>           value: "true"
> ```

### Postgres InstanceへTLSでアクセス

Postgresリソースを作成するとPostgres ServerのTLS対応が自動で行われます。
TLS証明書はCertificateリソースとして作成されます。

このTLS証明書のCA証明書をアプリケーション側に信頼させてTLS接続するように設定を変更します。

PostgreSQL JDBC Driverのデフォルトの`javax.net.ssl.SSLSocketFactory`実装である`org.postgresql.ssl.LibPQFactory`は`${HOME}/.postgresql/root.crt`のPEMファイルを信頼された証明書とみなすので、
Certificateリソースが作成したSecret(`vehicle-db-internal-ssl-secret`)の`ca.crt`をこのファイルにマウントします。

```yaml
cat <<'EOF' > /tmp/vehicle-api.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: vehicle-api
  name: vehicle-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vehicle-api
  template:
    metadata:
      labels:
        app: vehicle-api
    spec:
      containers:
      - image: ghcr.io/making/vehicle-api
        name: vehicle-api
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_CONFIG_IMPORT
          value: configtree:/workspace/config/
        - name: SPRING_DATASOURCE_URL
          value: jdbc:postgresql://vehicle-db.${spring.datasource.namespace}.svc.cluster.local:5432/${spring.datasource.dbname}
        - name: SPRING_DATASOURCE_HIKARI_DATASOURCEPROPERTIES_SSLMODE
          value: verify-full
        - name: SPRING_DATASOURCE_HIKARI_DATASOURCEPROPERTIES_SSLFACTORY          
          value: org.postgresql.ssl.LibPQFactory # Default
        - name: MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE
          value: health,info
        #! Tweak for less memory 
        - name: SPRING_DATASOURCE_HIKARI_MAXIMUMPOOLSIZE
          value: "4"
        - name: JAVA_TOOL_OPTIONS
          value: -XX:ReservedCodeCacheSize=32M -Xss512k -Duser.timezone=Asia/Tokyo
        - name: BPL_JVM_THREAD_COUNT
          value: "20"
        - name: SERVER_TOMCAT_THREADS_MAX
          value: "4"
        resources:
          limits:
            memory: 256Mi
          requests:
            memory: 256Mi
        volumeMounts:
        - name: vehicle-db
          mountPath: /workspace/config/spring/datasource
          readOnly: true
        - name: vehicle-db-cert
          mountPath: /home/cnb/.postgresql/root.crt
          subPath: ca.crt
          readOnly: true
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
            scheme: HTTP
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
            scheme: HTTP          
      volumes:
      - name: vehicle-db
        secret:
          secretName: vehicle-db-db-secret
      - name: vehicle-db-cert
        secret:
          secretName: vehicle-db-internal-ssl-secret
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: vehicle-api
  name: vehicle-api
spec:
  ports:
  - name: http
    port: 80
    targetPort: 8080
  selector:
    app: vehicle-api
EOF
kubectl apply -f /tmp/vehicle-api.yaml
```


次のコマンドでvehicle-apiにアクセスできることを確認します。

```
$ curl -s http://vehicle-api.default.svc.cluster.local/vehicles | jq .
[
  {
    "id": 1,
    "name": "Avalon"
  },
  {
    "id": 2,
    "name": "Corolla"
  },
  {
    "id": 3,
    "name": "Crown"
  },
  {
    "id": 4,
    "name": "Levin"
  },
  {
    "id": 5,
    "name": "Yaris"
  },
  {
    "id": 6,
    "name": "Vios"
  },
  {
    "id": 7,
    "name": "Glanza"
  },
  {
    "id": 8,
    "name": "Aygo"
  }
]
```

> もしCA証明書をマウントできていなければ例外がスローされ、Stack Trace中に次のメッセージが含まれます。
> ```
> Caused by: org.postgresql.util.PSQLException: Could not open SSL root certificate file /home/cnb/.postgresql/root.crt.
> ```
> 
### TBD: Postgres InstanceのデータをBackup

TBD

https://postgres-kubernetes.docs.pivotal.io/1-2/backup-restore.html
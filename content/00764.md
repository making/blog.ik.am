---
title: OrbStackのLinux Machine上にVMware Greenplum®をインストールするメモ
tags: ["OrbStack", "Greenplum", "Tanzu", "PostgreSQL"]
categories: ["Middleware", "RDBMS", "Greenplum"]
---

[VMware Greenplum®](https://network.tanzu.vmware.com/products/vmware-greenplum) を [OrbStack](https://orbstack.dev) の [Linux Machine](https://docs.orbstack.dev/machines/) 上にインストールしてみます。<br>
Linux MachineはWindows Subsystem for Linux (WSL)のように使える、Virtual Machineより軽量でContainerより寿命の長い仕組みです。

Coordinator 1台 (`gp-coordinator`) と Segment 2台 (`gp-segment1`, `gp-segment2`) の構成を作ります。本記事ではVMware Greenplum® 7.0.0-beta.5をインストールします。

基本的には [インストールガイド](https://docs.vmware.com/en/VMware-Greenplum/7/greenplum-database/install_guide-install_guide.html) にしたがって作業しました。 

**目次**
<!-- toc -->

### Linux Machineの作成

LinuxのDistroには [サポートされている](https://docs.vmware.com/en/VMware-Greenplum/7/greenplum-database/install_guide-platform-requirements-overview.html#operating-systems) Rocky Linux 8を使用します。

次のコマンドで3つのLinux Machineを作成します。検証した環境はApple SiliconのMacだったので `amd64` archを明示しました。

```bash
orb create -a amd64 rocky:8 gp-coordinator
```
```bash
orb create -a amd64 rocky:8 gp-segment1
```
```bash
orb create -a amd64 rocky:8 gp-segment2
```

Terminalを3つ開き、次のコマンドでそれぞれのシェルにアクセスします。

```bash
orb shell -m gp-coordinator
```

```bash
orb shell -m gp-segment1
```

```bash
orb shell -m gp-segment2
```

### OSの初期セットアップ

各ホスト上で次のコマンドを実行します

```bash
sudo yum -y install epel-release
sudo yum -y config-manager --set-enabled powertools
sudo yum -y install apr \
apr-util \
bash \
bzip2 \
curl \
lsof \
bind-utils \
krb5-libs \
libcgroup-tools \
libcurl \
libevent \
libxml2 \
libyaml \
zlib \
openldap \
openssh-clients \
openssh-server \
openssl \
openssl-libs \
sshpass \
perl \
python39 \
readline \
rsync \
R \
sed \
tar \
zip \
apr \
apr-util \
libyaml \
libevent \
java-11-openjdk-devel

echo 2 | sudo update-alternatives --config java

cat <<EOF | sudo tee -a /etc/sysctl.d/99-sysctl.conf > /dev/null
net.ipv4.ip_local_reserved_ports=65330
EOF
sudo sysctl --system

cat <<EOF | sudo tee -a /etc/security/limits.conf > /dev/null
* soft nofile 65536
* hard nofile 65536
EOF

sudo sed -i.bak -e 's/#Port/Port/' -e 's/#PubkeyAuthentication/PubkeyAuthentication/' /etc/ssh/sshd_config
sudo systemctl start sshd
sudo systemctl enable sshd

cat <<EOF | sudo tee /etc/hosts > /dev/null
$(dig +short gp-coordinator.orb.local) gp-coordinator
$(dig +short gp-segment1.orb.local) gp-segment1
$(dig +short gp-segment2.orb.local) gp-segment2
127.0.0.1 localhost
EOF
```

### VMware Greenplum® のダウンロード

VMware Greenplum® のrpmをダウンロードします。ここでは [`pivnet`](https://github.com/pivotal-cf/pivnet-cli) CLIを使用します。API Tokenは [こちら](https://network.tanzu.vmware.com/users/dashboard/edit-profile) から取得できます。

rpmファイルはMac上にダウンロードすることで、各ホストに共有されるので、以下のコマンドは `gp-coordinator` 上で行えば良いです。

```bash
cd /Users/${USER}/Downloads

curl -sL https://github.com/pivotal-cf/pivnet-cli/releases/download/v3.0.1/pivnet-darwin-amd64-3.0.1 > pivnet
chmod +x pivnet
sudo mv pivnet /usr/local/bin/
pivnet login --api-token=*********************-r
pivnet download-product-files --product-slug='vmware-greenplum' --release-version='7.0.0-beta.5' --glob='*.rpm'
```

### VMware Greenplum®のインストール

`gpadmin`ユーザーを作ってrpmをダウンロードしたインストールします。

`gp-coordinator`,`gp-segment1`, `gp-segment2` それぞれで以下を実行します。

```bash
sudo groupadd gpadmin
sudo useradd -m gpadmin -g gpadmin
echo gpadmin:Greenplum123 | sudo chpasswd
echo 'gpadmin ALL=(ALL) NOPASSWD: ALL' | sudo EDITOR='tee -a' visudo

sudo yum -y install ./greenplum-db-7.0.0-beta.5-el8-x86_64.rpm
sudo chown -R gpadmin:gpadmin /usr/local/greenplum*
sudo chgrp -R gpadmin /usr/local/greenplum*
```

Greenplum用の環境変数などが設定されたスクリプトを `.bashrc` で読み込むようにします。

```bash
cat <<EOF | sudo su - gpadmin bash -c 'tee -a /home/gpadmin/.bashrc'
source /usr/local/greenplum-db/greenplum_path.sh
EOF
```

### SSHの設定

各ノード間をパスワードレスでssh通信できるようにする必要があります。

まずは各ノードで次のコマンドを実行して鍵を生成します。

```bash
sudo su - gpadmin bash -c 'ssh-keygen -m PEM -t rsa -b 4096 -q -N "" -f /home/gpadmin/.ssh/id_rsa'
```

以下の作業は `gp-coordinator` 上でのみで行います。`gpadmin` ユーザーで作業します。

`gp-coordinator` の公開鍵を各ホストの `/home/gpadmin/.ssh/authorized_keys` に追記します。

```bash
sudo su - gpadmin

SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-coordinator
SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-segment1
SSHPASS=Greenplum123 sshpass -e ssh-copy-id -o StrictHostKeyChecking=no gp-segment2
```

次のコマンドで各ホストの公開鍵を各ホストの `/home/gpadmin/.ssh/known_hosts` に追記します。

```bash
cat <<EOF > hostfile_exkeys
gp-coordinator
gp-segment1
gp-segment2
EOF

gpssh-exkeys -f hostfile_exkeys
```

### VMware Greenplum®のセットアップ

以下の作業は `gp-coordinator` 上でのみで行います。引き続き `gpadmin` ユーザーで作業します。

次のコマンドで各ホスト用のディレクトリの作成をします。

```bash
sudo mkdir -p /data/coordinator
sudo chown gpadmin:gpadmin /data/coordinator

cat <<EOF > hostfile_gpssh_segonly
gp-segment1
gp-segment2
EOF

gpssh -f hostfile_gpssh_segonly -e 'sudo mkdir -p /data/primary'
gpssh -f hostfile_gpssh_segonly -e 'sudo mkdir -p /data/mirror'
gpssh -f hostfile_gpssh_segonly -e 'sudo chown -R gpadmin /data/*'
```

次のコマンドでVMware Greenplum®を初期化します。

```bash
mkdir -p gpconfigs
cat <<EOF > gpconfigs/hostfile_gpinitsystem
gp-segment1
gp-segment2
EOF

cp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/gpconfigs/gpinitsystem_config
sed -i.bak \
  -e 's|/data1/primary /data1/primary /data1/primary /data2/primary /data2/primary /data2/primary|/data/primary|' \
  -e 's|/data1/mirror /data1/mirror /data1/mirror /data2/mirror /data2/mirror /data2/mirror|/data/mirror|' \
  -e 's/#MIRROR_PORT_BASE/MIRROR_PORT_BASE/' \
  -e 's/#declare -a MIRROR_DATA_DIRECTORY/declare -a MIRROR_DATA_DIRECTORY/' \
  -e 's/COORDINATOR_HOSTNAME=cdw/COORDINATOR_HOSTNAME=gp-coordinator/' \
  gpconfigs/gpinitsystem_config

gpinitsystem -c gpconfigs/gpinitsystem_config -h gpconfigs/hostfile_gpinitsystem
```

次のようなログが出力され、確認が求められます。

```
20230920:21:32:19:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking configuration parameters, please wait...
20230920:21:32:19:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Reading Greenplum configuration file gpconfigs/gpinitsystem_config
20230920:21:32:19:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Locale has not been set in gpconfigs/gpinitsystem_config, will set to default value
20230920:21:32:20:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-No DATABASE_NAME set, will exit following template1 updates
20230920:21:32:20:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-COORDINATOR_MAX_CONNECT not set, will set to default value 250
20230920:21:32:20:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking configuration parameters, Completed
20230920:21:32:20:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing multi-home checks, please wait...
..
20230920:21:32:22:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Configuring build for standard array
20230920:21:32:23:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing multi-home checks, Completed
20230920:21:32:23:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Building primary segment instance array, please wait...
..
20230920:21:32:26:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Building group mirror array type , please wait...
..
20230920:21:32:29:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking Coordinator host
20230920:21:32:29:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking new segment hosts, please wait...
....
20230920:21:32:43:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Checking new segment hosts, Completed
20230920:21:32:43:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Database Creation Parameters
20230920:21:32:43:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20230920:21:32:43:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator Configuration
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator hostname       = gp-coordinator
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator port           = 5432
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator instance dir   = /data/coordinator/gpseg-1
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator LOCALE         = 
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum segment prefix   = gpseg
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator Database       = 
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator connections    = 250
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator buffers        = 128000kB
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Segment connections        = 750
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Segment buffers            = 128000kB
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Encoding                   = UNICODE
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Postgres param file        = Off
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Initdb to be used          = /usr/local/greenplum-db-7.0.0-beta.5/bin/initdb
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-GP_LIBRARY_PATH is         = /usr/local/greenplum-db-7.0.0-beta.5/lib
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-HEAP_CHECKSUM is           = on
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-HBA_HOSTNAMES is           = 0
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Ulimit check               = Passed
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Array host connect type    = Single hostname per node
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [1]      = ::1
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [2]      = 198.19.249.116
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [3]      = fd07:b51a:cc66:0:544e:b8ff:fe64:8e36
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Coordinator IP address [4]      = fe80::544e:b8ff:fe64:8e36
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Standby Coordinator             = Not Configured
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Number of primary segments = 1
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total Database segments    = 2
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Trusted shell              = ssh
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Number segment hosts       = 2
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Mirror port base           = 7000
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Number of mirror segments  = 1
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Mirroring config           = ON
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Mirroring type             = Group
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:----------------------------------------
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Primary Segment Configuration
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:----------------------------------------
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment1 	6000 	gp-segment1 	/data/primary/gpseg0 	2
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment2 	6000 	gp-segment2 	/data/primary/gpseg1 	3
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20230920:21:32:44:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Mirror Segment Configuration
20230920:21:32:45:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:---------------------------------------
20230920:21:32:45:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment2 	7000 	gp-segment2 	/data/mirror/gpseg0 	4
20230920:21:32:45:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-gp-segment1 	7000 	gp-segment1 	/data/mirror/gpseg1 	5

Continue with Greenplum creation Yy|Nn (default=N):
> 
```

`y`を入力すると、次のようなログが出力されます。

```
20230920:21:32:50:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Building the Coordinator instance database, please wait...
20230920:21:32:53:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Starting the Coordinator in admin mode
20230920:21:32:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing parallel build of primary segment instances
20230920:21:32:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Spawning parallel processes    batch [1], please wait...
..
20230920:21:32:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Waiting for parallel processes batch [1], please wait...
........................
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Parallel process exit status
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as completed           = 2
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as killed              = 0
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as failed              = 0
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Removing back out file
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-No errors generated from parallel processes
20230920:21:33:21:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Restarting the Greenplum instance in production mode
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Starting gpstop with args: -a -l /home/gpadmin/gpAdminLogs -m -d /data/coordinator/gpseg-1
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Gathering information and validating the environment...
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Obtaining Greenplum Coordinator catalog information
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Obtaining Segment details from coordinator...
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Greenplum Version: 'postgres (Greenplum Database) 7.0.0-beta.5 build commit:08189b6c918790e7bc32184a6661de14fe22c8d5'
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Commencing Coordinator instance shutdown with mode='smart'
20230920:21:33:21:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Coordinator segment instance directory=/data/coordinator/gpseg-1
20230920:21:33:23:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Stopping coordinator segment and waiting for user connections to finish ...
server shutting down
20230920:21:33:24:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Attempting forceful termination of any leftover coordinator process
20230920:21:33:24:039383 gpstop:gp-coordinator:gpadmin-[INFO]:-Terminating processes for segment /data/coordinator/gpseg-1
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Starting gpstart with args: -a -l /home/gpadmin/gpAdminLogs -d /data/coordinator/gpseg-1
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Gathering information and validating the environment...
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Greenplum Binary Version: 'postgres (Greenplum Database) 7.0.0-beta.5 build commit:08189b6c918790e7bc32184a6661de14fe22c8d5'
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Greenplum Catalog Version: '302307241'
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Starting Coordinator instance in admin mode
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-CoordinatorStart pg_ctl cmd is env GPSESSID=0000000000 GPERA=None $GPHOME/bin/pg_ctl -D /data/coordinator/gpseg-1 -l /data/coordinator/gpseg-1/log/startup.log -w -t 600 -o " -c gp_role=utility " start
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Obtaining Greenplum Coordinator catalog information
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Obtaining Segment details from coordinator...
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Setting new coordinator era
20230920:21:33:30:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Coordinator Started...
20230920:21:33:31:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Shutting down coordinator
20230920:21:33:38:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Commencing parallel segment instance startup, please wait...
.
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Process results...
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-   Successful segment starts                                            = 2
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-   Failed segment starts                                                = 0
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-   Skipped segment starts (segments are marked down in configuration)   = 0
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Successfully started 2 of 2 segment instances 
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-----------------------------------------------------
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Starting Coordinator instance gp-coordinator directory /data/coordinator/gpseg-1 
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-CoordinatorStart pg_ctl cmd is env GPSESSID=0000000000 GPERA=ab03d3b04e6ea60f_230920213330 $GPHOME/bin/pg_ctl -D /data/coordinator/gpseg-1 -l /data/coordinator/gpseg-1/log/startup.log -w -t 600 -o " -c gp_role=dispatch " start
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Command pg_ctl reports Coordinator gp-coordinator instance active
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Connecting to db template1 on host localhost
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-No standby coordinator configured.  skipping...
20230920:21:33:40:039763 gpstart:gp-coordinator:gpadmin-[INFO]:-Database successfully started
20230920:21:33:40:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Completed restart of Greenplum instance in production mode
20230920:21:33:40:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Creating core GPDB extensions
20230920:21:33:41:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Importing system collations
20230920:21:33:45:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Commencing parallel build of mirror segment instances
20230920:21:33:45:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Spawning parallel processes    batch [1], please wait...
..
20230920:21:33:45:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Waiting for parallel processes batch [1], please wait...
.........
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Parallel process exit status
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as completed           = 2
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as killed              = 0
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Total processes marked as failed              = 0
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:------------------------------------------------
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Scanning utility log file for any warning messages
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Log file scan check passed
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Greenplum Database instance successfully created
20230920:21:33:55:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-------------------------------------------------------
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-To complete the environment configuration, please 
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-update gpadmin .bashrc file with the following
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-1. Ensure that the greenplum_path.sh file is sourced
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-2. Add "export COORDINATOR_DATA_DIRECTORY=/data/coordinator/gpseg-1"
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-   to access the Greenplum scripts for this instance:
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-   or, use -d /data/coordinator/gpseg-1 option for the Greenplum scripts
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-   Example gpstate -d /data/coordinator/gpseg-1
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Script log file = /home/gpadmin/gpAdminLogs/gpinitsystem_20230920.log
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-To remove instance, run gpdeletesystem utility
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-To initialize a Standby Coordinator Segment for this Greenplum instance
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Review options for gpinitstandby
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-------------------------------------------------------
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-The Coordinator /data/coordinator/gpseg-1/pg_hba.conf post gpinitsystem
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-has been configured to allow all hosts within this new
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-array to intercommunicate. Any hosts external to this
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-new array must be explicitly added to this file
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-Refer to the Greenplum Admin support guide which is
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-located in the /usr/local/greenplum-db-7.0.0-beta.5/docs directory
20230920:21:33:56:036256 gpinitsystem:gp-coordinator:gpadmin-[INFO]:-------------------------------------------------------
```

`Greenplum Database instance successfully created` と出力されたのでセットアップが成功したように見えます。

### データベースの作成

データベースの作成はPostgreSQLと基本的に同じです。以下の作業は `gp-coordinator` 上でのみで行います。引き続き `gpadmin` ユーザーで作業します。

```bash
createdb test
```

### VMware Greenplum®へのアクセス

VMware Greenplum®へのアクセスもPostgreSQLと基本的に同じです。以下の作業は `gp-coordinator` 上でのみで行います。引き続き `gpadmin` ユーザーで作業します。


```bash
$ psql -d test
psql (12.12)
Type "help" for help.
```

次のSQLを実行します。

```sql
CREATE TABLE IF NOT EXISTS organization
(
    organization_id   BIGINT PRIMARY KEY,
    organization_name VARCHAR(255) NOT NULL
);
INSERT INTO organization(organization_id, organization_name) VALUES(1, 'foo');
INSERT INTO organization(organization_id, organization_name) VALUES(2, 'bar');
```

デフォルではPrimary Keyでデータが分散されるようです。`gp_segment_id`というカラムでデータがどのセグメントに配置されているか確認することができます。


```sql
test=# select organization_id,organization_name,gp_segment_id from organization;
 organization_id | organization_name | gp_segment_id 
-----------------+-------------------+---------------
               2 | bar               |             0
               1 | foo               |             1
(2 rows)
```

とりあえず、ここまで確認できました。
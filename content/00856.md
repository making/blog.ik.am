---
title: Foundry Localã‚’ä½¿ã£ã¦Spring AIã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹
tags: ["Foundry Local", "OpenAI", "Spring AI", "Azure", "Machine Learning"]
categories: ["AI", "LLM", "Foundry Local"]
---

[Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)ã¯ã€MicrosoftãŒæä¾›ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç’°å¢ƒã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§ç°¡å˜ã«ç®¡ç†ãƒ»å®Ÿè¡Œã§ãã¾ã™ã€‚
OpenAI APIäº’æ›ã®APIã‚’æä¾›ã—ã¦ã„ã‚‹ãŸã‚ã€Spring AIãªã©ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚‚ç°¡å˜ã«åˆ©ç”¨å¯èƒ½ã§ã™ã€‚


**ç›®æ¬¡**
<!-- toc -->


### Foundry Localã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

Macã®å ´åˆã¯brewã‚’ä½¿ç”¨ã—ã¦ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚

```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

### ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰

åˆæœŸçŠ¶æ…‹ã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```bash

$ foundry model list
Alias                          Device     Task               File Size    License      Model ID            
-----------------------------------------------------------------------------------------------
phi-4                          GPU        chat-completion    8.37 GB      MIT          Phi-4-generic-gpu   
                               CPU        chat-completion    10.16 GB     MIT          Phi-4-generic-cpu   
--------------------------------------------------------------------------------------------------------
mistral-7b-v0.2                GPU        chat-completion    4.07 GB      apache-2.0   mistralai-Mistral-7B-Instruct-v0-2-generic-gpu
                               CPU        chat-completion    4.07 GB      apache-2.0   mistralai-Mistral-7B-Instruct-v0-2-generic-cpu
-------------------------------------------------------------------------------------------------------------------------------------
phi-3.5-mini                   GPU        chat-completion    2.16 GB      MIT          Phi-3.5-mini-instruct-generic-gpu
                               CPU        chat-completion    2.53 GB      MIT          Phi-3.5-mini-instruct-generic-cpu
------------------------------------------------------------------------------------------------------------------------
phi-3-mini-128k                GPU        chat-completion    2.13 GB      MIT          Phi-3-mini-128k-instruct-generic-gpu
                               CPU        chat-completion    2.54 GB      MIT          Phi-3-mini-128k-instruct-generic-cpu
---------------------------------------------------------------------------------------------------------------------------
phi-3-mini-4k                  GPU        chat-completion    2.13 GB      MIT          Phi-3-mini-4k-instruct-generic-gpu
                               CPU        chat-completion    2.53 GB      MIT          Phi-3-mini-4k-instruct-generic-cpu
-------------------------------------------------------------------------------------------------------------------------
deepseek-r1-14b                GPU        chat-completion    10.27 GB     MIT          deepseek-r1-distill-qwen-14b-generic-gpu
-------------------------------------------------------------------------------------------------------------------------------
deepseek-r1-7b                 GPU        chat-completion    5.58 GB      MIT          deepseek-r1-distill-qwen-7b-generic-gpu
------------------------------------------------------------------------------------------------------------------------------
qwen2.5-0.5b                   GPU        chat-completion    0.68 GB      apache-2.0   qwen2.5-0.5b-instruct-generic-gpu
                               CPU        chat-completion    0.80 GB      apache-2.0   qwen2.5-0.5b-instruct-generic-cpu
------------------------------------------------------------------------------------------------------------------------
qwen2.5-1.5b                   GPU        chat-completion    1.51 GB      apache-2.0   qwen2.5-1.5b-instruct-generic-gpu
                               CPU        chat-completion    1.78 GB      apache-2.0   qwen2.5-1.5b-instruct-generic-cpu
------------------------------------------------------------------------------------------------------------------------
qwen2.5-coder-0.5b             GPU        chat-completion    0.52 GB      apache-2.0   qwen2.5-coder-0.5b-instruct-generic-gpu
                               CPU        chat-completion    0.80 GB      apache-2.0   qwen2.5-coder-0.5b-instruct-generic-cpu
------------------------------------------------------------------------------------------------------------------------------
qwen2.5-coder-7b               GPU        chat-completion    4.73 GB      apache-2.0   qwen2.5-coder-7b-instruct-generic-gpu
                               CPU        chat-completion    6.16 GB      apache-2.0   qwen2.5-coder-7b-instruct-generic-cpu
----------------------------------------------------------------------------------------------------------------------------
qwen2.5-coder-1.5b             GPU        chat-completion    1.25 GB      apache-2.0   qwen2.5-coder-1.5b-instruct-generic-gpu
                               CPU        chat-completion    1.78 GB      apache-2.0   qwen2.5-coder-1.5b-instruct-generic-cpu
------------------------------------------------------------------------------------------------------------------------------
phi-4-mini                     GPU        chat-completion    3.72 GB      MIT          Phi-4-mini-instruct-generic-gpu
----------------------------------------------------------------------------------------------------------------------
phi-4-mini-reasoning           GPU        chat-completion    3.15 GB      MIT          Phi-4-mini-reasoning-generic-gpu
                               CPU        chat-completion    4.52 GB      MIT          Phi-4-mini-reasoning-generic-cpu
-----------------------------------------------------------------------------------------------------------------------
qwen2.5-14b                    CPU        chat-completion    11.06 GB     apache-2.0   qwen2.5-14b-instruct-generic-cpu
-----------------------------------------------------------------------------------------------------------------------
qwen2.5-7b                     GPU        chat-completion    5.20 GB      apache-2.0   qwen2.5-7b-instruct-generic-gpu
                               CPU        chat-completion    6.16 GB      apache-2.0   qwen2.5-7b-instruct-generic-cpu
----------------------------------------------------------------------------------------------------------------------
qwen2.5-coder-14b              GPU        chat-completion    8.79 GB      apache-2.0   qwen2.5-coder-14b-instruct-generic-gpu
                               CPU        chat-completion    11.06 GB     apache-2.0   qwen2.5-coder-14b-instruct-generic-cpu
```

ä»Šå›ã¯phi-4-miniã‚’ä½¿ç”¨ã—ã¦ã¿ã¾ã™ã€‚

```bash
foundry model download phi-4-mini
foundry model load phi-4-mini
```

Startã—ã¦ã€Runningã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚ã¾ãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®URLã‚‚ç¢ºèªã§ãã¾ã™ã€‚

```bash
$ foundry service status
ğŸŸ¢ Model management service is running on http://localhost:5273/openai/status
```

ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã‚’æ¬¡ã®APIã§ç¢ºèªã§ãã¾ã™ã€‚

```bash
$ curl -s http://localhost:5273/openai/models | jq .
[
  "Phi-4-mini-instruct-generic-gpu"
]
```

OpenAI APIäº’æ›ã®APIã«å¯¾ã—ã¦ã€æ¬¡ã®ã‚ˆã†ã«`curl`ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã§ãã¾ã™ã€‚

```bash
curl -s http://localhost:5273/v1/chat/completions \
  --json '{
   "model": "Phi-4-mini-instruct-generic-gpu",
   "messages": [
      {"role": "user", "content": "Give me a joke."}
   ]
 }' | jq .
```

æ¬¡ã®ã‚ˆã†ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã£ã¦ãã¾ã™ã€‚

```json
{
  "model": null,
  "choices": [
    {
      "delta": {
        "role": "assistant",
        "content": "Sure, here's a classic joke for you:\n\nWhy don't scientists trust atoms?\n\nBecause they make up everything!",
        "name": null,
        "tool_call_id": null,
        "function_call": null,
        "tool_calls": []
      },
      "message": {
        "role": "assistant",
        "content": "Sure, here's a classic joke for you:\n\nWhy don't scientists trust atoms?\n\nBecause they make up everything!",
        "name": null,
        "tool_call_id": null,
        "function_call": null,
        "tool_calls": []
      },
      "index": 0,
      "finish_reason": "stop",
      "finish_details": null,
      "logprobs": null
    }
  ],
  "usage": null,
  "system_fingerprint": null,
  "service_tier": null,
  "created": 1750299210,
  "CreatedAt": "2025-06-19T02:13:30+00:00",
  "id": "chat.id.1",
  "StreamEvent": null,
  "IsDelta": false,
  "Successful": true,
  "error": null,
  "HttpStatusCode": 0,
  "HeaderValues": null,
  "object": "chat.completion"
}
```

### Spring AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®åˆ©ç”¨

ã“ã®ãƒ–ãƒ­ã‚°ã§ã‚ˆãä½¿ç”¨ã—ã¦ã„ã‚‹[Spring AIã®ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒª](https://github.com/making/hello-spring-ai)ã‹ã‚‰Foundry Localã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã¿ã¾ã™ã€‚

```bash
git clone https://github.com/making/hello-spring-ai
cd hello-spring-ai
./mvnw clean package -DskipTests=true
java -jar target/hello-spring-ai-0.0.1-SNAPSHOT.jar \
  --spring.ai.openai.base-url=http://localhost:5273 \
  --spring.ai.openai.api-key=dummy \
  --spring.ai.openai.chat.options.model=Phi-4-mini-instruct-generic-gpu \
  --spring.ai.openai.chat.options.temperature=0
```

http://localhost:8080 ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€ãƒãƒ£ãƒƒãƒˆUIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

![image](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/914e4afc-abe4-42ea-8eb1-346be221c9ac.png)

å³ä¸Šã®â„¹ï¸ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨æ¥ç¶šã—ã¦ã„ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

![image](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/b0ae419b-a22b-45ee-9a0c-63d299be7ea0.png)

ãƒãƒ£ãƒƒãƒˆUIä¸Šã§ä¼šè©±ãŒã§ãã¾ã—ãŸã€‚

![image](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/7fc32537-a7a0-40ce-bff3-74adc379162b.png)

Tool Callingã§ç¾åœ¨æ™‚åˆ»ã‚’å›ç­”ã§ãã‚‹ã‹è©¦ã—ã¦ã¿ã¾ã—ãŸãŒã€Phi-4-miniã¯Tool Callingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚

![image](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1852/7741c05e-3bf4-4a89-9ef8-042307bf65dc.png)

`~/.foundry/cache/models/foundry.modelinfo.json`ã‚’è¦‹ã‚‹é™ã‚Šã€æœ¬ç¨¿åŸ·ç­†æ™‚ç‚¹ã§Tool Callingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹(`supportsToolCalling`ãŒ`true`)ãƒ¢ãƒ‡ãƒ«ã¯ãªã„ã‚ˆã†ã§ã™ã€‚

### Spring AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ

ã›ã£ã‹ããªã®ã§ã€0ã‹ã‚‰Spring AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ã€Foundry Localã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã¿ã¾ã™ã€‚

Spring Initializrã§æ¬¡ã®ã‚ˆã†ã«è¨­å®šã—ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

```bash
curl -s https://start.spring.io/starter.tgz \
       -d artifactId=demo-spring-ai \
       -d name=demo-spring-ai \
       -d baseDir=demo-spring-ai  \
       -d packageName=com.example \
       -d dependencies=spring-ai-openai,web,actuator,configuration-processor,prometheus,native \
       -d type=maven-project \
       -d applicationName=DemoSpringAiApplication | tar -xzvf -
cd demo-spring-ai
```

```java
cat <<'EOF' > src/main/java/com/example/HelloController.java
package com.example;

import org.springframework.ai.chat.client.ChatClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class HelloController {

	private final ChatClient chatClient;

	public HelloController(ChatClient.Builder chatClientBuilder) {
		this.chatClient = chatClientBuilder.build();
	}

	@GetMapping(path = "/")
	public String hello(@RequestParam(defaultValue = "Tell me a joke") String prompt) {
		return this.chatClient.prompt().messages().user(prompt).call().content();
	}

}
EOF
```

```properties
cat <<EOF > src/main/resources/application.properties
spring.ai.openai.base-url=http://localhost:5273
spring.ai.openai.api-key=dummy
spring.ai.openai.chat.options.model=Phi-4-mini-instruct-generic-gpu
spring.ai.openai.chat.options.temperature=0
EOF
```

ç°¡å˜ã§ã™ã­ã€‚ãƒ“ãƒ«ãƒ‰ã—ã¦å®Ÿè¡Œã—ã¾ã—ã‚‡ã†ã€‚

```bash
./mvnw clean package -DskipTests=true
java -jar target/demo-spring-ai-0.0.1-SNAPSHOT.jar
```

`Why is the sky blue?`ã¨ã„ã†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ã£ã¦ã¿ã¾ã™ã€‚

```bash
$ curl "localhost:8080?prompt=Why%20is%20the%20sky%20blue%3F"
The sky appears blue due to Rayleigh scattering, which is the scattering of light by particles much smaller than the wavelength of the light. Sunlight, which appears white, is actually made up of all colors of the rainbow. When sunlight enters Earth's atmosphere, it collides with molecules and small particles in the air. Blue light, which has a shorter wavelength, is scattered in all directions much more than other colors with longer wavelengths. This scattering causes the sky to look blue to our eyes when we look up during the day. At sunrise and sunset, the sky can appear red or orange because the light has to pass through more atmosphere, which scatters the shorter wavelengths and allows the longer wavelengths to reach our eyes.
```

ç„¡äº‹ã«å›ç­”ãŒè¿”ã‚Šã¾ã—ãŸã€‚

---

æœ¬ç¨¿ã§ã¯Foundry Localã‚’ä½¿ã£ã¦ã€OpenAI APIäº’æ›ã®APIã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã—ã€Spring AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚

ãªãŠã€ä¾‹ãˆã°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’Azure OpenAI Serviceã«åˆ‡ã‚Šæ›¿ãˆãŸã„å ´åˆã¯ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãªãã€æ¬¡ã®ã‚ˆã†ãªãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¨­å®šã™ã‚Œã°è‰¯ã„ã§ã™ã€‚

```properties
spring.ai.openai.base-url=https://xxxxxxxxxxxxxxx.openai.azure.com
spring.ai.openai.chat.options.model=gpt-4.1-mini
spring.ai.openai.chat.completions-path=/openai/deployments/${spring.ai.openai.chat.options.model}/chat/completions?api-version=2024-02-01
spring.ai.openai.api-key=${AZURE_OPEN_AI_API_KEY}
```

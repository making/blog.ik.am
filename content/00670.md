---
title: Tanzu Community EditionをDocker上にインストールするメモ
tags: ["Kubernetes", "vSphere", "TKG", "Tanzu", "Cluster API", "MetalLB", "TCE", "Docker"]
categories: ["Dev", "CaaS", "Kubernetes", "TKG", "TCE", "Docker"]
---

[Tanzu Community Edition](https://tanzucommunityedition.io) (TCE) は [Cluster API](https://github.com/kubernetes-sigs/cluster-api) を使ってKubernetesクラスタを管理するソリューションである、
[Tanzu Kubernetes Grid](https://tanzu.vmware.com/kubernetes-grid) (TKG) のオープンソース版です。

TCEはTKGのupstream版という位置付けであり、例えるとFedoraとRed Hat Enterprise Linuxのような関係です。

TCEのデプロイ方法はTKGと同じであるManagement Cluster / Workload Cluster方式と、単一のクラスタだけ作成するStandalone Cluster方式を選べます。
対応しているIaaS ProviderはTKGと同じくvSphere、AWS、Azureに加えてDockerが追加されています。どの環境でも同じようにクラスタを管理できます。

Standalone ClusterをMacのDocker上で作成してもKindでクラスタを作成するのと大差がなくて面白くないので、
ここではDocker上でManagement Cluster / Workload Cluster方式を試します。

Management Clusterを作成する分、リソースを余分に消費しますが、TKGをIaaS上で構築する前にDockerで試したい場合などに有用です。

**目次**
<!-- toc -->

### Tanzu CLIのインストール

まずはTCE用の`tanzu` CLIをインストールします。TKGとは同梱されているプラグインが異なります。

Mac用のCLIをインストールします。

```
curl -sL https://github.com/vmware-tanzu/community-edition/releases/download/v0.9.1/tce-darwin-amd64-v0.9.1.tar.gz > ~/Downloads/tce-darwin-amd64-v0.9.1.tar.gz
tar xzvf ~/Downloads/tce-darwin-amd64-v0.9.1.tar.gz
cd tce-darwin-amd64-v0.9.1
./install.sh
```

バージョンを確認します。

```
$ tanzu version
version: v0.2.1
buildDate: 2021-09-29
sha: ceaa474
```

同梱されているプラグインリストは次の通りです。

```
$ tanzu plugin list
  NAME                LATEST VERSION  DESCRIPTION                                                        REPOSITORY  VERSION  STATUS         
  builder             v0.2.1          Build Tanzu components                                             core-admin  v0.2.1   installed      
  cluster             v0.2.1          Kubernetes cluster operations                                      core        v0.2.1   installed      
  codegen                             Tanzu code generation tool                                         core-admin           not installed  
  conformance         v0.9.0          Run Sonobuoy conformance tests against clusters                    tce         v0.9.1   installed      
  diagnostics         v0.9.0          Cluster diagnostics                                                tce         v0.9.1   installed      
  kubernetes-release  v0.2.1          Kubernetes release operations                                      core        v0.2.1   installed      
  login               v0.2.1          Login to the platform                                              core        v0.2.1   installed      
  management-cluster  v0.2.1          Kubernetes management cluster operations                           core        v0.2.1   installed      
  package             v0.2.1          Tanzu package management                                           core        v0.2.1   installed      
  pinniped-auth       v0.2.1          Pinniped authentication operations (usually not directly invoked)  core        v0.2.1   installed      
  standalone-cluster  v0.9.0          Create clusters without a dedicated management cluster             tce         v0.9.1   installed      
  test                                Test the CLI                                                       core-admin           not installed
```

REPOSITORY列が `tce` となっているものはTCEでのみ提供されているプラグインです。

### Dockerの準備

ドキュメントは [こちら](https://tanzucommunityedition.io/docs/latest/docker-install-mgmt/) 
推奨されているDockerの最低リソースは以下の通りです。

* 6 GB of RAM
* 15 GB of local machine disk storage for images
* 4 CPUs

今回は次の環境にインストールします。

![image](https://user-images.githubusercontent.com/106908/137592442-6f189986-39e0-4c6c-bd46-1c461187326a.png)

必須ではありませんが、Docker上の既存のリソースを削除します。

```
docker kill $(docker ps -q)
docker system prune -a --volumes -f 
```

これも必須ではないですが、TCEでクラスタを作成する際に次のイメージのみDockerHubからpullします。
DockerHubのrate limitに引っかかる場合は、事前にこのイメージをpullしておくて余計なエラーに遭わなくて済みます。

```
docker pull kindest/haproxy:v20210715-a6da3463
```

### Management Clusterの作成

まずはManagement Clusterを作成します。
`tanzu management-cluster create --ui` でWebブラウザで値を入力しながら作成できますが、Dockerの場合は特にパラメータの入力が不要なので、コマンドラインのみで作成します。

次のコマンドでManagement ClusterをDocker上に作成できます。

```
export MGMT_CLUSTER_NAME=salmon
tanzu management-cluster create -i docker --name ${MGMT_CLUSTER_NAME} -v 10 --plan dev --ceip-participation=false
```

完了するまで15分ほどかかりました。

次のコマンドで作成したManagement Clusterを確認できます。

```
$ tanzu management-cluster get
  NAME    NAMESPACE   STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES       
  salmon  tkg-system  running  1/1           1/1      v1.21.2+vmware.1  management  


Details:

NAME                                                       READY  SEVERITY  REASON  SINCE  MESSAGE
/salmon                                                    True                     19m           
├─ClusterInfrastructure - DockerCluster/salmon             True                     20m           
├─ControlPlane - KubeadmControlPlane/salmon-control-plane  True                     19m           
│ └─Machine/salmon-control-plane-f6mcc                     True                     19m           
└─Workers                                                                                         
  └─MachineDeployment/salmon-md-0                                                                 
    └─Machine/salmon-md-0-6d79b77757-kqssf                 True                     19m           


Providers:

  NAMESPACE                          NAME                   TYPE                    PROVIDERNAME  VERSION  WATCHNAMESPACE  
  capd-system                        infrastructure-docker  InfrastructureProvider  docker        v0.3.23                  
  capi-kubeadm-bootstrap-system      bootstrap-kubeadm      BootstrapProvider       kubeadm       v0.3.23                  
  capi-kubeadm-control-plane-system  control-plane-kubeadm  ControlPlaneProvider    kubeadm       v0.3.23                  
  capi-system                        cluster-api            CoreProvider            cluster-api   v0.3.23  
```

このManagement Clusterにアクセスするためのkubeconfigは次のコマンドで取得できます。

```
tanzu management-cluster kubeconfig get ${MGMT_CLUSTER_NAME} --admin
kubectl config use-context ${MGMT_CLUSTER_NAME}-admin@${MGMT_CLUSTER_NAME}
```

NodeとPodのリストを確認します。

```
$ kubectl get node -owide
NAME                           STATUS   ROLES                  AGE   VERSION                               INTERNAL-IP   EXTERNAL-IP   OS-IMAGE           KERNEL-VERSION     CONTAINER-RUNTIME
salmon-control-plane-f6mcc     Ready    control-plane,master   29m   v1.21.2+vmware.1-360497810732255795   172.18.0.4    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269
salmon-md-0-6d79b77757-kqssf   Ready    <none>                 28m   v1.21.2+vmware.1-360497810732255795   172.18.0.5    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269

$ kubectl get pod -A  
NAMESPACE                           NAME                                                             READY   STATUS    RESTARTS   AGE
capd-system                         capd-controller-manager-5885f59558-mkwnq                         2/2     Running   0          5m39s
capi-kubeadm-bootstrap-system       capi-kubeadm-bootstrap-controller-manager-6494884869-4rcb7       2/2     Running   0          7m1s
capi-kubeadm-control-plane-system   capi-kubeadm-control-plane-controller-manager-857d687b9d-jqcnw   2/2     Running   0          6m19s
capi-system                         capi-controller-manager-778bd4dfb9-s92qs                         2/2     Running   1          7m39s
capi-webhook-system                 capi-controller-manager-9995bdc94-9nwt8                          2/2     Running   0          8m4s
capi-webhook-system                 capi-kubeadm-bootstrap-controller-manager-68845b65f8-ndg2q       2/2     Running   0          7m27s
capi-webhook-system                 capi-kubeadm-control-plane-controller-manager-9847c6747-nnz2n    2/2     Running   0          6m48s
cert-manager                        cert-manager-77f6fb8fd5-r5hpn                                    1/1     Running   1          9m40s
cert-manager                        cert-manager-cainjector-6bd4cff7bb-2s7tb                         1/1     Running   1          9m41s
cert-manager                        cert-manager-webhook-fbfcb9d6c-7gvjp                             1/1     Running   0          9m39s
kube-system                         antrea-agent-2lhnn                                               2/2     Running   0          67s
kube-system                         antrea-agent-tkndc                                               2/2     Running   0          80s
kube-system                         antrea-controller-5d68c8db5-6xnbf                                1/1     Running   0          80s
kube-system                         coredns-8dcb5c56b-2qlpn                                          1/1     Running   0          10m
kube-system                         coredns-8dcb5c56b-9whg8                                          1/1     Running   0          10m
kube-system                         etcd-salmon-control-plane-f6mcc                                  1/1     Running   0          10m
kube-system                         kube-apiserver-salmon-control-plane-f6mcc                        1/1     Running   0          10m
kube-system                         kube-controller-manager-salmon-control-plane-f6mcc               1/1     Running   0          10m
kube-system                         kube-proxy-4r6dg                                                 1/1     Running   0          10m
kube-system                         kube-proxy-tzfxx                                                 1/1     Running   0          10m
kube-system                         kube-scheduler-salmon-control-plane-f6mcc                        1/1     Running   0          10m
kube-system                         metrics-server-774c86899d-r6b8x                                  1/1     Running   0          99s
tkg-system                          kapp-controller-6499b8866-xtcbr                                  1/1     Running   0          8m36s
tkg-system                          tanzu-addons-controller-manager-56754c6985-gn6p5                 1/1     Running   0          2m16s
tkg-system                          tanzu-capabilities-controller-manager-6ff97656b8-87jkh           1/1     Running   0          9m52s
tkr-system                          tkr-controller-manager-6bc455b5d4-xvnxx                          1/1     Running   0          9m1s
```

### Workload Clusterの作成

次にWorkload Clusterを作成します。

次のコマンドでWorkload Clusterを作成できます。

```
export WORKLOAD_CLUSTER_NAME=ikra
tanzu cluster create ${WORKLOAD_CLUSTER_NAME} -v 10 --plan dev
```


完了するまで5分ほどかかりました。

次のコマンドで作成したWorkload Clusterを確認できます。

```
$ tanzu cluster get ikra
  NAME  NAMESPACE  STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES   
  ikra  default    running  1/1           1/1      v1.21.2+vmware.1  <none>  
ℹ  

Details:

NAME                                                     READY  SEVERITY  REASON  SINCE  MESSAGE
/ikra                                                    True                     44m           
├─ClusterInfrastructure - DockerCluster/ikra             True                     45m           
├─ControlPlane - KubeadmControlPlane/ikra-control-plane  True                     44m           
│ └─Machine/ikra-control-plane-xpnf2                     True                     44m           
└─Workers                                                                                       
  └─MachineDeployment/ikra-md-0                                                                 
    └─Machine/ikra-md-0-6b5984c77d-n7d8f                 True                     44m
```

次のコマンドでクラスタリストを確認できます。

```
$ tanzu cluster list --include-management-cluster
  NAME    NAMESPACE   STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES       PLAN  
  ikra    default     running  1/1           1/1      v1.21.2+vmware.1  <none>      dev   
  salmon  tkg-system  running  1/1           1/1      v1.21.2+vmware.1  management  dev   
```

これらのクラスタはManagement Clusterのリソースとして管理されています。machineリソースリストを確認します。

```
$ kubectl --context ${MGMT_CLUSTER_NAME}-admin@${MGMT_CLUSTER_NAME} get machine -A
NAMESPACE    NAME                           PROVIDERID                                PHASE     VERSION
default      ikra-control-plane-xpnf2       docker:////ikra-control-plane-xpnf2       Running   v1.21.2+vmware.1
default      ikra-md-0-6b5984c77d-n7d8f     docker:////ikra-md-0-6b5984c77d-n7d8f     Running   v1.21.2+vmware.1
tkg-system   salmon-control-plane-f6mcc     docker:////salmon-control-plane-f6mcc     Running   v1.21.2+vmware.1
tkg-system   salmon-md-0-6d79b77757-kqssf   docker:////salmon-md-0-6d79b77757-kqssf   Running   v1.21.2+vmware.1
```

このWorkload Clusterにアクセスするためのkubeconfigは次のコマンドで取得できます。

```
tanzu cluster kubeconfig get ${WORKLOAD_CLUSTER_NAME} --admin
kubectl config use-context ${WORKLOAD_CLUSTER_NAME}-admin@${WORKLOAD_CLUSTER_NAME}
```

NodeとPodのリストを確認します。

```
$ kubectl get node -owide
NAME                         STATUS   ROLES                  AGE     VERSION                               INTERNAL-IP   EXTERNAL-IP   OS-IMAGE           KERNEL-VERSION     CONTAINER-RUNTIME
ikra-control-plane-xpnf2     Ready    control-plane,master   3m55s   v1.21.2+vmware.1-360497810732255795   172.18.0.6    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269
ikra-md-0-6b5984c77d-n7d8f   Ready    <none>                 3m20s   v1.21.2+vmware.1-360497810732255795   172.18.0.7    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269

$ kubectl get pod -A
NAMESPACE     NAME                                                     READY   STATUS    RESTARTS   AGE
kube-system   antrea-agent-dtggt                                       2/2     Running   0          2m38s
kube-system   antrea-agent-qdt9c                                       2/2     Running   0          2m38s
kube-system   antrea-controller-55f7c855b9-6bzxf                       1/1     Running   0          2m38s
kube-system   coredns-8dcb5c56b-cnj6c                                  1/1     Running   0          3m51s
kube-system   coredns-8dcb5c56b-l2l2q                                  1/1     Running   0          3m51s
kube-system   etcd-ikra-control-plane-xpnf2                            1/1     Running   0          3m57s
kube-system   kube-apiserver-ikra-control-plane-xpnf2                  1/1     Running   0          3m57s
kube-system   kube-controller-manager-ikra-control-plane-xpnf2         1/1     Running   0          3m57s
kube-system   kube-proxy-5wlg6                                         1/1     Running   0          3m24s
kube-system   kube-proxy-ctp2r                                         1/1     Running   0          3m51s
kube-system   kube-scheduler-ikra-control-plane-xpnf2                  1/1     Running   0          3m57s
kube-system   metrics-server-58c8689755-pnlk7                          1/1     Running   0          2m43s
tkg-system    kapp-controller-69c645fd79-8hpzp                         1/1     Running   0          3m51s
tkg-system    tanzu-capabilities-controller-manager-6ff97656b8-tgc49   1/1     Running   0          3m51s
```

ちなみにDocker上には次のようなコンテナが起動しています。nodeごとに1コンテナと、controlplaneに対するロードバランサとしてHA Proxyがクラスタ毎に起動しています。

```
$ docker ps

CONTAINER ID   IMAGE                                                         COMMAND                  CREATED          STATUS          PORTS                                  NAMES
fca90c507e2e   projects.registry.vmware.com/tkg/kind/node:v1.21.2_vmware.1   "/usr/local/bin/entr…"   4 minutes ago    Up 4 minutes                                           ikra-md-0-6b5984c77d-n7d8f
5f5cdae7258e   projects.registry.vmware.com/tkg/kind/node:v1.21.2_vmware.1   "/usr/local/bin/entr…"   5 minutes ago    Up 5 minutes    45609/tcp, 127.0.0.1:45609->6443/tcp   ikra-control-plane-xpnf2
3f4d786b1253   kindest/haproxy:v20210715-a6da3463                            "haproxy -sf 7 -W -d…"   5 minutes ago    Up 5 minutes    40777/tcp, 0.0.0.0:40777->6443/tcp     ikra-lb
6cfbf47d8c00   projects.registry.vmware.com/tkg/kind/node:v1.21.2_vmware.1   "/usr/local/bin/entr…"   36 minutes ago   Up 36 minutes                                          salmon-md-0-6d79b77757-kqssf
265b2e0c5ca9   projects.registry.vmware.com/tkg/kind/node:v1.21.2_vmware.1   "/usr/local/bin/entr…"   38 minutes ago   Up 37 minutes   40041/tcp, 127.0.0.1:40041->6443/tcp   salmon-control-plane-f6mcc
90b5235ac3b7   kindest/haproxy:v20210715-a6da3463                            "haproxy -sf 7 -W -d…"   38 minutes ago   Up 38 minutes   41679/tcp, 0.0.0.0:41679->6443/tcp     salmon-lb
```

### Packageの確認

TCEやTKGではCarvelの [Packaging API](https://carvel.dev/kapp-controller/docs/latest/packaging/) を使って機能を追加できます。

初めから利用可能なPackageリストを次のコマンドで確認可能です。

```
$ tanzu package available list -A
/ Retrieving available packages... 
  NAME                                                DISPLAY-NAME                       SHORT-DESCRIPTION                                                                                                                                                                                       NAMESPACE   
  addons-manager.tanzu.vmware.com                     tanzu-addons-manager               This package provides TKG addons lifecycle management capabilities.                                                                                                                                     tkg-system  
  ako-operator.tanzu.vmware.com                       ako-operator                       NSX Advanced Load Balancer using ako-operator                                                                                                                                                           tkg-system  
  antrea.tanzu.vmware.com                             antrea                             networking and network security solution for containers                                                                                                                                                 tkg-system  
  calico.tanzu.vmware.com                             calico                             Networking and network security solution for containers.                                                                                                                                                tkg-system  
  kapp-controller.tanzu.vmware.com                    kapp-controller                    Kubernetes package manager                                                                                                                                                                              tkg-system  
  load-balancer-and-ingress-service.tanzu.vmware.com  load-balancer-and-ingress-service  Provides L4+L7 load balancing for TKG clusters running on vSphere                                                                                                                                       tkg-system  
  metrics-server.tanzu.vmware.com                     metrics-server                     Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.                                                                             tkg-system  
  pinniped.tanzu.vmware.com                           pinniped                           Pinniped provides identity services to Kubernetes.                                                                                                                                                      tkg-system  
  vsphere-cpi.tanzu.vmware.com                        vsphere-cpi                        The Cluster API brings declarative, Kubernetes-style APIs to cluster creation, configuration and management. Cluster API Provider for vSphere is a concrete implementation of Cluster API for vSphere.  tkg-system  
  vsphere-csi.tanzu.vmware.com                        vsphere-csi                        vSphere CSI provider                                                                                                                                                                                    tkg-system
```

このリストは `kubectl get package -A` でも確認できます。

既にインストールされているPackageリストは次のコマンドで確認できます。

```
$ tanzu package installed list -A
/ Retrieving installed packages... 
  NAME            PACKAGE-NAME                     PACKAGE-VERSION  STATUS               NAMESPACE   
  antrea          antrea.tanzu.vmware.com                           Reconcile succeeded  tkg-system  
  metrics-server  metrics-server.tanzu.vmware.com                   Reconcile succeeded  tkg-system 
```

このリストは `kubectl get packageinstall -A` でも確認できます。

TCEには [TCE用のPackage](https://tanzucommunityedition.io/docs/latest/package-management/) がいくつか用意されています。

TCE用のPackageを利用可能にするために次のようにPackage Repositoryを追加します。

```
tanzu package repository add tce-repo \
  --url projects.registry.vmware.com/tce/main:0.9.1 \
  --namespace tanzu-package-repo-global
```

利用可能なPackage Repositoryリストを次のコマンド

```
$ tanzu package repository list -A
/ Retrieving repositories... 
  NAME        REPOSITORY                                                                  STATUS               DETAILS  NAMESPACE                  
  tce-repo    projects.registry.vmware.com/tce/main:0.9.1                                 Reconciling                   tanzu-package-repo-global  
  tanzu-core  projects.registry.vmware.com/tkg/packages/core/repo:v1.21.2_vmware.1-tkg.1  Reconcile succeeded           tkg-system   
```

このリストは `kubectl get packagerepository -A` でも確認できます。STATUS列が `Reconcile succeeded` になれば、RepositoryのPackage情報が取得できています。

再度、利用可能なPackageリストを確認するとTCE用のPackageが追加されていることがわかります。


```
$ tanzu package available list -A 
/ Retrieving available packages... 
  NAME                                                DISPLAY-NAME                       SHORT-DESCRIPTION                                                                                                                                                                                       NAMESPACE                  
  cert-manager.community.tanzu.vmware.com             cert-manager                       Certificate management                                                                                                                                                                                  tanzu-package-repo-global  
  contour.community.tanzu.vmware.com                  Contour                            An ingress controller                                                                                                                                                                                   tanzu-package-repo-global  
  external-dns.community.tanzu.vmware.com             external-dns                       This package provides DNS synchronization functionality.                                                                                                                                                tanzu-package-repo-global  
  fluent-bit.community.tanzu.vmware.com               fluent-bit                         Fluent Bit is a fast Log Processor and Forwarder                                                                                                                                                        tanzu-package-repo-global  
  gatekeeper.community.tanzu.vmware.com               gatekeeper                         policy management                                                                                                                                                                                       tanzu-package-repo-global  
  grafana.community.tanzu.vmware.com                  grafana                            Visualization and analytics software                                                                                                                                                                    tanzu-package-repo-global  
  harbor.community.tanzu.vmware.com                   Harbor                             OCI Registry                                                                                                                                                                                            tanzu-package-repo-global  
  knative-serving.community.tanzu.vmware.com          knative-serving                    Knative Serving builds on Kubernetes to support deploying and serving of applications and functions as serverless containers                                                                            tanzu-package-repo-global  
  local-path-storage.community.tanzu.vmware.com       local-path-storage                 This package provides local path node storage and primarily supports RWO AccessMode.                                                                                                                    tanzu-package-repo-global  
  multus-cni.community.tanzu.vmware.com               multus-cni                         This package provides the ability for enabling attaching multiple network interfaces to pods in Kubernetes                                                                                              tanzu-package-repo-global  
  prometheus.community.tanzu.vmware.com               prometheus                         A time series database for your metrics                                                                                                                                                                 tanzu-package-repo-global  
  velero.community.tanzu.vmware.com                   velero                             Disaster recovery capabilities                                                                                                                                                                          tanzu-package-repo-global  
  addons-manager.tanzu.vmware.com                     tanzu-addons-manager               This package provides TKG addons lifecycle management capabilities.                                                                                                                                     tkg-system                 
  ako-operator.tanzu.vmware.com                       ako-operator                       NSX Advanced Load Balancer using ako-operator                                                                                                                                                           tkg-system                 
  antrea.tanzu.vmware.com                             antrea                             networking and network security solution for containers                                                                                                                                                 tkg-system                 
  calico.tanzu.vmware.com                             calico                             Networking and network security solution for containers.                                                                                                                                                tkg-system                 
  kapp-controller.tanzu.vmware.com                    kapp-controller                    Kubernetes package manager                                                                                                                                                                              tkg-system                 
  load-balancer-and-ingress-service.tanzu.vmware.com  load-balancer-and-ingress-service  Provides L4+L7 load balancing for TKG clusters running on vSphere                                                                                                                                       tkg-system                 
  metrics-server.tanzu.vmware.com                     metrics-server                     Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.                                                                             tkg-system                 
  pinniped.tanzu.vmware.com                           pinniped                           Pinniped provides identity services to Kubernetes.                                                                                                                                                      tkg-system                 
  vsphere-cpi.tanzu.vmware.com                        vsphere-cpi                        The Cluster API brings declarative, Kubernetes-style APIs to cluster creation, configuration and management. Cluster API Provider for vSphere is a concrete implementation of Cluster API for vSphere.  tkg-system                 
  vsphere-csi.tanzu.vmware.com                        vsphere-csi                        vSphere CSI provider                                                                                                                                                                                    tkg-system 
```

### Packageのインストール

試しに、一つPackageをインストールしてみます。次のコマンドで確認できるように、Docker Providerの場合はStorageClassが設定されていません。

```
$ kubectl get storageclass
No resources found
```

Docker Provider用に [Local Path Storage](https://tanzucommunityedition.io/docs/latest/package-readme-local-path-storage-0.0.20/) Packageが用意されているので、これをインストールします。

ここではPackageリソースを管理するnamespaceとして `tce-package-install` namespaceを作成します。
次のコマンドでLocal Path Storage Packageをインストールします。

```
kubectl create ns tce-package-install
tanzu package install local-path-storage --package-name local-path-storage.community.tanzu.vmware.com -v 0.0.20 -n tce-package-install
```

次のコマンドでLocal Path Storage Packageがインストールされたことを確認します。

```
$ tanzu package installed list -A
/ Retrieving installed packages... 
  NAME                PACKAGE-NAME                                   PACKAGE-VERSION  STATUS               NAMESPACE            
  local-path-storage  local-path-storage.community.tanzu.vmware.com  0.0.20           Reconcile succeeded  tce-package-install  
  antrea              antrea.tanzu.vmware.com                                         Reconcile succeeded  tkg-system           
  metrics-server      metrics-server.tanzu.vmware.com                                 Reconcile succeeded  tkg-system 
```

Packageでインストールされるソフトウェアは [Appリソース](https://carvel.dev/kapp-controller/docs/latest/app-overview/) によってReconcileされます。
次のコマンドでAppリソースのリストを確認できます。

```
$ kubectl get app -A
NAMESPACE             NAME                 DESCRIPTION           SINCE-DEPLOY   AGE
tce-package-install   local-path-storage   Reconcile succeeded   3s             100s
tkg-system            antrea               Reconcile succeeded   11s            48m
tkg-system            metrics-server       Reconcile succeeded   5m22s          48m
```

次のコマンドでAppリソースでどのようなリソースが管理されているかを確認できます。

```
$ kubectl get app -n tce-package-install local-path-storage -oyaml
apiVersion: kappctrl.k14s.io/v1alpha1
kind: App
metadata:
  creationTimestamp: "2021-10-16T16:33:34Z"
  finalizers:
  - finalizers.kapp-ctrl.k14s.io/delete
  generation: 1
  name: local-path-storage
  namespace: tce-package-install
  ownerReferences:
  - apiVersion: packaging.carvel.dev/v1alpha1
    blockOwnerDeletion: true
    controller: true
    kind: PackageInstall
    name: local-path-storage
    uid: ad2f2ea2-7ba8-411f-ad79-10f87c31e420
  resourceVersion: "5371"
  uid: 149b915b-a9c3-4d53-9b16-a810f942674f
spec:
  deploy:
  - kapp: {}
  fetch:
  - imgpkgBundle:
      image: projects.registry.vmware.com/tce/local-path-storage@sha256:e0db08cc6e83efb1f772ab9714d78900b5634146c266954abc805461a005beb1
  serviceAccountName: local-path-storage-tce-package-install-sa
  template:
  - ytt:
      paths:
      - config/
  - kbld:
      paths:
      - '-'
      - .imgpkg/images.yml
status:
  conditions:
  - status: "True"
    type: ReconcileSucceeded
  consecutiveReconcileSuccesses: 3
  deploy:
    exitCode: 0
    finished: true
    startedAt: "2021-10-16T16:35:11Z"
    stdout: |-
      Target cluster 'https://100.64.0.1:443' (nodes: ikra-control-plane-xpnf2, 1+)
      04:35:11PM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreanetworkpolicystats"}
      04:35:11PM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreaclusternetworkpolicystats"}
      04:35:11PM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"networkpolicystats"}
      Changes
      Namespace  Name  Kind  Conds.  Age  Op  Op st.  Wait to  Rs  Ri
      Op:      0 create, 0 delete, 0 update, 0 noop
      Wait to: 0 reconcile, 0 delete, 0 noop
      Succeeded
    updatedAt: "2021-10-16T16:35:11Z"
  fetch:
    exitCode: 0
    startedAt: "2021-10-16T16:35:05Z"
    stdout: |
      apiVersion: vendir.k14s.io/v1alpha1
      directories:
      - contents:
        - imgpkgBundle:
            image: projects.registry.vmware.com/tce/local-path-storage@sha256:e0db08cc6e83efb1f772ab9714d78900b5634146c266954abc805461a005beb1
          path: .
        path: "0"
      kind: LockConfig
    updatedAt: "2021-10-16T16:35:11Z"
  friendlyDescription: Reconcile succeeded
  inspect:
    exitCode: 0
    stdout: |-
      Target cluster 'https://100.64.0.1:443' (nodes: ikra-control-plane-xpnf2, 1+)
      04:35:11PM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreaclusternetworkpolicystats"}
      04:35:11PM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"networkpolicystats"}
      04:35:11PM: info: Resources: Ignoring group version: schema.GroupVersionResource{Group:"stats.antrea.tanzu.vmware.com", Version:"v1alpha1", Resource:"antreanetworkpolicystats"}
      Resources in app 'local-path-storage-ctrl'
      Namespace                 Name                                     Kind                Owner    Conds.  Rs  Ri  Age
      (cluster)                 local-path                               StorageClass        kapp     -       ok  -   1m
      ^                         local-path-provisioner-bind              ClusterRoleBinding  kapp     -       ok  -   1m
      ^                         local-path-provisioner-role              ClusterRole         kapp     -       ok  -   1m
      ^                         tanzu-local-path-storage                 Namespace           kapp     -       ok  -   1m
      tanzu-local-path-storage  local-path-config                        ConfigMap           kapp     -       ok  -   1m
      ^                         local-path-provisioner                   Deployment          kapp     2/2 t   ok  -   1m
      ^                         local-path-provisioner-6cdfc79dd5        ReplicaSet          cluster  -       ok  -   1m
      ^                         local-path-provisioner-6cdfc79dd5-bbb2k  Pod                 cluster  4/4 t   ok  -   1m
      ^                         local-path-provisioner-service-account   ServiceAccount      kapp     -       ok  -   1m
      Rs: Reconcile state
      Ri: Reconcile information
      9 resources
      Succeeded
    updatedAt: "2021-10-16T16:35:11Z"
  observedGeneration: 1
  template:
    exitCode: 0
    stderr: |
      resolve | final: rancher/local-path-provisioner:v0.0.20 -> projects.registry.vmware.com/tce/local-path-provisioner@sha256:6434e827349036958783c1f81b01838b5d7316c1275a25ba0f76ea7a89455231
    updatedAt: "2021-10-16T16:35:11Z"
```

> 上記の例ではマニフェストがimgpkgの [bundle形式](https://carvel.dev/imgpkg/docs/latest/) で配布されています。
> 実際のマニフェスト(YAML)は次のコマンドでダウンロードできます。
> 
> ```
> imgpkg pull -b projects.registry.vmware.com/tce/local-path-storage@sha256:e0db08cc6e83efb1f772ab9714d78900b5634146c266954abc805461a005beb1 -o /tmp/local-path-storage
> ```
> 
> 次のようなファイル群です。
> 
> ```
> $ find /tmp/local-path-storage 
> /tmp/local-path-storage
> /tmp/local-path-storage/kbld-config.yaml
> /tmp/local-path-storage/.imgpkg
> /tmp/local-path-storage/.imgpkg/images.yml
> /tmp/local-path-storage/.imgpkg/bundle.yaml
> /tmp/local-path-storage/config
> /tmp/local-path-storage/config/overlays
> /tmp/local-path-storage/config/overlays/overlay-storageclass.yaml
> /tmp/local-path-storage/config/overlays/overlay-namespace.yaml
> /tmp/local-path-storage/config/values.yaml
> /tmp/local-path-storage/config/upstream
> /tmp/local-path-storage/config/upstream/local-path-storage.yaml
> /tmp/local-path-storage/config/upstream/local-path-storage.yaml/local-path-storage.yaml
> /tmp/local-path-storage/vendir.lock.yml
> /tmp/local-path-storage/vendir.yml
> ```

次のコマンドでlocal-path-provisionerが起動していることがわかります。

```
$ kubectl get -n tanzu-local-path-storage pod
NAME                                      READY   STATUS    RESTARTS   AGE
local-path-provisioner-6cdfc79dd5-bbb2k   1/1     Running   0          4m19s
```

また次のコマンドでStorageClassが設定されたこともわかります。

```
$ kubectl get storageclass                  
NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  4m47s
```

### アプリケーションのデプロイ

Workload Clusterにアプリケーションをデプロイしてみます。
その前に、Docker Providerの場合はデフォルトでType=LoadBalancerなServiceを利用できないので、
[MetalLB](https://metallb.universe.tf/) をインストールします。

#### MetalLBのインストール

次のコマンドでMetalLBをインストールします。MetalLBのIPレンジはDockerのNetwork(172.18.0.0/16)の中から指定します。

```
METALLB_START_IP=172.18.0.200
METALLB_END_IP=172.18.0.254

mkdir -p metallb
curl -sL https://raw.githubusercontent.com/metallb/metallb/v0.10.3/manifests/namespace.yaml > metallb/namespace.yaml
curl -sL https://raw.githubusercontent.com/metallb/metallb/v0.10.3/manifests/metallb.yaml > metallb/metallb.yaml
kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)" --dry-run=client -o yaml > metallb/secret.yaml

cat > metallb/configmap.yaml << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    address-pools:
    - name: default
      protocol: layer2
      addresses:
      - ${METALLB_START_IP}-${METALLB_END_IP}
EOF
kubectl apply -f metallb/namespace.yaml -f metallb/metallb.yaml -f metallb/secret.yaml -f metallb/configmap.yaml
```

次のコマンドでMetalLBが起動していることを確認します。

```
$ kubectl get pod -n metallb-system -owide
NAME                         READY   STATUS    RESTARTS   AGE   IP           NODE                         NOMINATED NODE   READINESS GATES
controller-77c44876d-lcwb9   1/1     Running   0          18s   100.96.1.7   ikra-md-0-6b5984c77d-n7d8f   <none>           <none>
speaker-k9jwh                1/1     Running   0          18s   172.18.0.6   ikra-control-plane-xpnf2     <none>           <none>
speaker-kxlxs                1/1     Running   0          18s   172.18.0.7   ikra-md-0-6b5984c77d-n7d8f   <none>           <none>
```

#### Load Balancerの動作確認

次にサンプルアプリケーションをデプロイします。

```
kubectl create deployment demo --image=making/hello-world --dry-run=client -o=yaml > /tmp/deployment.yaml
echo --- >> /tmp/deployment.yaml
kubectl create service loadbalancer demo --tcp=80:8080 --dry-run=client -o=yaml >> /tmp/deployment.yaml
kubectl apply -f /tmp/deployment.yaml
```

次のコマンドでPodとServiceを確認します。ServiceのExternal IPにMetalLBに設定した範囲内のIPが設定されていることを確認してください。

```
$ kubectl get pod,svc -l app=demo
NAME                       READY   STATUS    RESTARTS   AGE
pod/demo-cfb66fb57-mmg4s   1/1     Running   0          4s

NAME           TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)        AGE
service/demo   LoadBalancer   100.71.98.113   172.18.0.200   80:30071/TCP   4s
```

> Macで試した時、DockerのNetwork(172.18.0.0/16)にはホスト側から直接アクセスできませんでした。Linuxでは直接アクセスできました。直接アクセスできないのは不便なので、[kwt](https://github.com/vmware-tanzu/carvel-kwt) を使って
> k8sクラスタ内へ直接アクセス可能にします。次のコマンドを別のターミナルで実行してください。
> 
> ```
> sudo -E kwt net start
> ```
> 
> kwtに関しては [こちらの記事](https://ik.am/entries/649) も参照してください。なお、Windowsでは利用できません。
> これでServiceのExternal IP(172.18.0.200)にアクセスできるようになります。次のコマンドでアプリケーションにアクセスしてくだbundleさい。

```
$ curl http://172.18.0.200   
Hello World!
```

確認が終わったらリソースを削除します。

```
kubectl delete -f /tmp/deployment.yaml 
```

#### Persistent Volumeの動作確認

次にPersistent Volumeを使ったアプリケーションを試します。
次のコマンドでPostgreSQLをインストールします。

```
cat <<EOF > /tmp/demo-db.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: demo-db
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1G
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-db
spec:
  selector:
    matchLabels:
      app: demo-db
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: demo-db
    spec:
      initContainers:
      - name: remove-lost-found
        image: busybox
        command:          
        - sh
        - -c
        - |
          rm -fr /var/lib/postgresql/data/lost+found
        volumeMounts:
        - name: demo-db
          mountPath: /var/lib/postgresql/data
      containers:
      - image: postgres:11
        name: postgres
        env:
        - name: POSTGRES_INITDB_ARGS
          value: "--encoding=UTF-8 --locale=C"
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: demo-db
              key: postgres-db
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: demo-db
              key: postgres-user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: demo-db
              key: postgres-password
        ports:
        - containerPort: 5432
          name: demo-db
        volumeMounts:
        - name: demo-db
          mountPath: /var/lib/postgresql/data
      volumes:
      - name: demo-db
        persistentVolumeClaim:
          claimName: demo-db
---
apiVersion: v1
kind: Service
metadata:
  name: demo-db
spec:
  ports:
  - port: 5432
  selector:
    app: demo-db
---
apiVersion: v1
kind: Secret
metadata:
  name: demo-db 
stringData:
  postgres-user: demo
  postgres-password: demo
  postgres-db: demo
EOF
kubectl apply -f /tmp/demo-db.yaml
```

次のコマンドを実行し、PostgreSQLが起動していること、PVが作成されていることを確認してください。

```
$ kubectl get pod,pv,pvc              
NAME                           READY   STATUS    RESTARTS   AGE
pod/demo-db-78c47d5589-4gxdf   1/1     Running   0          35s
pod/kwt-net                    1/1     Running   0          10h

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS   REASON   AGE
persistentvolume/pvc-f48b28ca-363f-44b9-8e76-3086ee38ca1c   1G         RWO            Delete           Bound    default/demo-db   local-path              32s

NAME                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/demo-db   Bound    pvc-f48b28ca-363f-44b9-8e76-3086ee38ca1c   1G         RWO            local-path     35s
```

kwtが起動している状態であれば、次のコマンドでPostgreSQLにアクセスできます。

```
$ PGPASSWORD=demo psql -h demo-db.default.svc.cluster.local -U demo demo

psql (13.4, server 11.13 (Debian 11.13-1.pgdg90+1))
Type "help" for help.

demo=# 
```

確認が終わったらリソースを削除します。

```
kubectl delete -f /tmp/demo-db.yaml 
```

### Workload Clusterのスケールアウト

次のコマンドでWorkload Clusterを3台にスケールアウトします。

```
tanzu cluster scale ikra -w 3
```

次のコマンドでクラスタの情報を確認します。

```
$ tanzu cluster get ikra --show-group-members
  NAME  NAMESPACE  STATUS   CONTROLPLANE  WORKERS  KUBERNETES        ROLES   
  ikra  default    running  1/1           3/3      v1.21.2+vmware.1  <none>  
ℹ  

Details:

NAME                                                     READY  SEVERITY  REASON  SINCE  MESSAGE
/ikra                                                    True                     12h           
├─ClusterInfrastructure - DockerCluster/ikra             True                     12h           
├─ControlPlane - KubeadmControlPlane/ikra-control-plane  True                     12h           
│ └─Machine/ikra-control-plane-xpnf2                     True                     12h           
└─Workers                                                                                       
  └─MachineDeployment/ikra-md-0                                                                 
    ├─Machine/ikra-md-0-6b5984c77d-8scgf                 True                     89s           
    ├─Machine/ikra-md-0-6b5984c77d-n7d8f                 True                     12h           
    └─Machine/ikra-md-0-6b5984c77d-sht5z                 True                     88s 
```

Node一覧を確認します。

```
$ kubectl get node -o wide   
NAME                         STATUS   ROLES                  AGE   VERSION                               INTERNAL-IP   EXTERNAL-IP   OS-IMAGE           KERNEL-VERSION     CONTAINER-RUNTIME
ikra-control-plane-xpnf2     Ready    control-plane,master   12h   v1.21.2+vmware.1-360497810732255795   172.18.0.6    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269
ikra-md-0-6b5984c77d-8scgf   Ready    <none>                 29s   v1.21.2+vmware.1-360497810732255795   172.18.0.8    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269
ikra-md-0-6b5984c77d-n7d8f   Ready    <none>                 12h   v1.21.2+vmware.1-360497810732255795   172.18.0.7    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269
ikra-md-0-6b5984c77d-sht5z   Ready    <none>                 29s   v1.21.2+vmware.1-360497810732255795   172.18.0.9    <none>        Ubuntu 20.04 LTS   5.10.47-linuxkit   containerd://1.3.3-14-g449e9269
```

### Workload Clusterの削除

検証が終われば、次のコマンドでWorkload Clusterを削除します。

```
tanzu cluster delete ikra -y
```

### Management Clusterの削除


検証が終われば、次のコマンドでManagement Clusterを削除します。

```
tanzu management-cluster delete salmon -y
```

---

Tanzu Community EditionをDockerで試しました。
同じようにvSphere、AWS、Azureでもクラスタの管理ができます。もちろんIaaS固有のパラメータの設定は必要です。
Cluster APIをベースとしたオープンソースであり、フリーで利用可能なので、是非いろいろ試してみてください。
Tanzu Kubernetes Gridを使っている人も検証用の選択肢が増えて良いのではないでしょうか。

[次の記事](/entries/671) ではこの環境にCert Manager, Contour, Prometheus, Grafana Packageをインストールします。
